{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1752996558398,
     "user": {
      "displayName": "azka nuril",
      "userId": "09044520640447098125"
     },
     "user_tz": -420
    },
    "id": "_d9IPS3TQSl-"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, confusion_matrix, classification_report\n",
    "from yellowbrick.classifier import ROCAUC\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 449,
     "status": "ok",
     "timestamp": 1752996558853,
     "user": {
      "displayName": "azka nuril",
      "userId": "09044520640447098125"
     },
     "user_tz": -420
    },
    "id": "zvbgcAp1QnQz",
    "outputId": "f9a256a1-cc9c-48c8-ad1d-d6075e1140a4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tanggal</th>\n",
       "      <th>Terakhir</th>\n",
       "      <th>Pembukaan</th>\n",
       "      <th>Tertinggi</th>\n",
       "      <th>Terendah</th>\n",
       "      <th>Vol.</th>\n",
       "      <th>Perubahan%</th>\n",
       "      <th>date</th>\n",
       "      <th>avg_signed_sentiment</th>\n",
       "      <th>count_positive</th>\n",
       "      <th>count_negative</th>\n",
       "      <th>count_neutral</th>\n",
       "      <th>total_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-07-04</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.68</td>\n",
       "      <td>3.71</td>\n",
       "      <td>3.65</td>\n",
       "      <td>91,14M</td>\n",
       "      <td>-0,27%</td>\n",
       "      <td>2025-07-04</td>\n",
       "      <td>-0.000960</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-07-03</td>\n",
       "      <td>3.68</td>\n",
       "      <td>3.71</td>\n",
       "      <td>3.73</td>\n",
       "      <td>3.68</td>\n",
       "      <td>119,67M</td>\n",
       "      <td>0,00%</td>\n",
       "      <td>2025-07-03</td>\n",
       "      <td>0.052033</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-07-02</td>\n",
       "      <td>3.68</td>\n",
       "      <td>3.65</td>\n",
       "      <td>3.70</td>\n",
       "      <td>3.64</td>\n",
       "      <td>220,27M</td>\n",
       "      <td>-0,54%</td>\n",
       "      <td>2025-07-02</td>\n",
       "      <td>-0.007767</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>3.70</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.67</td>\n",
       "      <td>212,37M</td>\n",
       "      <td>-1,07%</td>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>-0.018503</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>3.74</td>\n",
       "      <td>3.84</td>\n",
       "      <td>3.84</td>\n",
       "      <td>3.73</td>\n",
       "      <td>271,93M</td>\n",
       "      <td>-2,35%</td>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>-0.124553</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-06-26</td>\n",
       "      <td>3.83</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.83</td>\n",
       "      <td>3.75</td>\n",
       "      <td>171,43M</td>\n",
       "      <td>1,86%</td>\n",
       "      <td>2025-06-26</td>\n",
       "      <td>0.198789</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-06-25</td>\n",
       "      <td>3.76</td>\n",
       "      <td>3.83</td>\n",
       "      <td>3.83</td>\n",
       "      <td>3.73</td>\n",
       "      <td>164,26M</td>\n",
       "      <td>-0,53%</td>\n",
       "      <td>2025-06-25</td>\n",
       "      <td>-0.072154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-06-24</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.82</td>\n",
       "      <td>3.90</td>\n",
       "      <td>3.77</td>\n",
       "      <td>281,59M</td>\n",
       "      <td>1,61%</td>\n",
       "      <td>2025-06-24</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-06-23</td>\n",
       "      <td>3.72</td>\n",
       "      <td>3.73</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.66</td>\n",
       "      <td>222,07M</td>\n",
       "      <td>-1,85%</td>\n",
       "      <td>2025-06-23</td>\n",
       "      <td>-0.374837</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2025-06-20</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.74</td>\n",
       "      <td>3.84</td>\n",
       "      <td>3.74</td>\n",
       "      <td>516,18M</td>\n",
       "      <td>-0,26%</td>\n",
       "      <td>2025-06-20</td>\n",
       "      <td>-0.111262</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2025-06-19</td>\n",
       "      <td>3.80</td>\n",
       "      <td>3.90</td>\n",
       "      <td>3.92</td>\n",
       "      <td>3.80</td>\n",
       "      <td>355,41M</td>\n",
       "      <td>-3,55%</td>\n",
       "      <td>2025-06-19</td>\n",
       "      <td>-0.155275</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2025-06-18</td>\n",
       "      <td>3.94</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.96</td>\n",
       "      <td>3.90</td>\n",
       "      <td>140,88M</td>\n",
       "      <td>-0,51%</td>\n",
       "      <td>2025-06-18</td>\n",
       "      <td>-0.138931</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2025-06-17</td>\n",
       "      <td>3.96</td>\n",
       "      <td>4.01</td>\n",
       "      <td>4.03</td>\n",
       "      <td>3.96</td>\n",
       "      <td>125,77M</td>\n",
       "      <td>-0,75%</td>\n",
       "      <td>2025-06-17</td>\n",
       "      <td>0.047399</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2025-06-16</td>\n",
       "      <td>3.99</td>\n",
       "      <td>3.98</td>\n",
       "      <td>4.01</td>\n",
       "      <td>3.96</td>\n",
       "      <td>155,45M</td>\n",
       "      <td>-0,25%</td>\n",
       "      <td>2025-06-16</td>\n",
       "      <td>-0.126163</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2025-06-13</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.02</td>\n",
       "      <td>4.05</td>\n",
       "      <td>3.98</td>\n",
       "      <td>283,83M</td>\n",
       "      <td>-1,72%</td>\n",
       "      <td>2025-06-13</td>\n",
       "      <td>0.163476</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2025-06-12</td>\n",
       "      <td>4.07</td>\n",
       "      <td>4.07</td>\n",
       "      <td>4.10</td>\n",
       "      <td>4.06</td>\n",
       "      <td>113,85M</td>\n",
       "      <td>0,00%</td>\n",
       "      <td>2025-06-12</td>\n",
       "      <td>0.046693</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2025-06-11</td>\n",
       "      <td>4.07</td>\n",
       "      <td>4.13</td>\n",
       "      <td>4.14</td>\n",
       "      <td>4.06</td>\n",
       "      <td>196,56M</td>\n",
       "      <td>-1,93%</td>\n",
       "      <td>2025-06-11</td>\n",
       "      <td>0.037650</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2025-06-10</td>\n",
       "      <td>4.15</td>\n",
       "      <td>4.10</td>\n",
       "      <td>4.16</td>\n",
       "      <td>4.10</td>\n",
       "      <td>179,83M</td>\n",
       "      <td>1,22%</td>\n",
       "      <td>2025-06-10</td>\n",
       "      <td>-0.054510</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2025-06-05</td>\n",
       "      <td>4.10</td>\n",
       "      <td>4.11</td>\n",
       "      <td>4.14</td>\n",
       "      <td>4.05</td>\n",
       "      <td>230,13M</td>\n",
       "      <td>0,49%</td>\n",
       "      <td>2025-06-05</td>\n",
       "      <td>0.179834</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2025-06-04</td>\n",
       "      <td>4.08</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.08</td>\n",
       "      <td>279,76M</td>\n",
       "      <td>-2,86%</td>\n",
       "      <td>2025-06-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2025-06-03</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.21</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.12</td>\n",
       "      <td>277,90M</td>\n",
       "      <td>0,00%</td>\n",
       "      <td>2025-06-03</td>\n",
       "      <td>-0.014521</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2025-06-02</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.36</td>\n",
       "      <td>4.39</td>\n",
       "      <td>4.20</td>\n",
       "      <td>389,54M</td>\n",
       "      <td>-5,62%</td>\n",
       "      <td>2025-06-02</td>\n",
       "      <td>-0.114793</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2025-05-28</td>\n",
       "      <td>4.45</td>\n",
       "      <td>4.36</td>\n",
       "      <td>4.45</td>\n",
       "      <td>4.32</td>\n",
       "      <td>466,13M</td>\n",
       "      <td>1,83%</td>\n",
       "      <td>2025-05-28</td>\n",
       "      <td>-0.198505</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2025-05-27</td>\n",
       "      <td>4.37</td>\n",
       "      <td>4.32</td>\n",
       "      <td>4.37</td>\n",
       "      <td>4.28</td>\n",
       "      <td>180,03M</td>\n",
       "      <td>1,16%</td>\n",
       "      <td>2025-05-27</td>\n",
       "      <td>0.302433</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2025-05-26</td>\n",
       "      <td>4.32</td>\n",
       "      <td>4.35</td>\n",
       "      <td>4.35</td>\n",
       "      <td>4.26</td>\n",
       "      <td>149,42M</td>\n",
       "      <td>-0,69%</td>\n",
       "      <td>2025-05-26</td>\n",
       "      <td>-0.128274</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2025-05-23</td>\n",
       "      <td>4.35</td>\n",
       "      <td>4.37</td>\n",
       "      <td>4.37</td>\n",
       "      <td>4.33</td>\n",
       "      <td>187,46M</td>\n",
       "      <td>1,16%</td>\n",
       "      <td>2025-05-23</td>\n",
       "      <td>-0.020540</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2025-05-22</td>\n",
       "      <td>4.30</td>\n",
       "      <td>4.28</td>\n",
       "      <td>4.31</td>\n",
       "      <td>4.24</td>\n",
       "      <td>208,29M</td>\n",
       "      <td>0,94%</td>\n",
       "      <td>2025-05-22</td>\n",
       "      <td>0.045951</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2025-05-21</td>\n",
       "      <td>4.26</td>\n",
       "      <td>4.21</td>\n",
       "      <td>4.31</td>\n",
       "      <td>4.21</td>\n",
       "      <td>256,02M</td>\n",
       "      <td>1,19%</td>\n",
       "      <td>2025-05-21</td>\n",
       "      <td>-0.153046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2025-05-20</td>\n",
       "      <td>4.21</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.28</td>\n",
       "      <td>4.17</td>\n",
       "      <td>209,58M</td>\n",
       "      <td>-0,47%</td>\n",
       "      <td>2025-05-20</td>\n",
       "      <td>0.048572</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2025-05-19</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.26</td>\n",
       "      <td>4.20</td>\n",
       "      <td>145,94M</td>\n",
       "      <td>-0,47%</td>\n",
       "      <td>2025-05-19</td>\n",
       "      <td>0.331064</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2025-05-16</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.31</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.16</td>\n",
       "      <td>289,34M</td>\n",
       "      <td>-0,47%</td>\n",
       "      <td>2025-05-16</td>\n",
       "      <td>-0.176841</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2025-05-15</td>\n",
       "      <td>4.27</td>\n",
       "      <td>4.14</td>\n",
       "      <td>4.31</td>\n",
       "      <td>4.13</td>\n",
       "      <td>537,15M</td>\n",
       "      <td>4,40%</td>\n",
       "      <td>2025-05-15</td>\n",
       "      <td>0.075178</td>\n",
       "      <td>18.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2025-05-14</td>\n",
       "      <td>4.09</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.09</td>\n",
       "      <td>3.96</td>\n",
       "      <td>461,64M</td>\n",
       "      <td>6,51%</td>\n",
       "      <td>2025-05-14</td>\n",
       "      <td>-0.085922</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2025-05-09</td>\n",
       "      <td>3.84</td>\n",
       "      <td>3.81</td>\n",
       "      <td>3.84</td>\n",
       "      <td>3.76</td>\n",
       "      <td>147,64M</td>\n",
       "      <td>1,32%</td>\n",
       "      <td>2025-05-09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2025-05-08</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.91</td>\n",
       "      <td>3.96</td>\n",
       "      <td>3.78</td>\n",
       "      <td>224,12M</td>\n",
       "      <td>-3,07%</td>\n",
       "      <td>2025-05-08</td>\n",
       "      <td>-0.209798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2025-05-07</td>\n",
       "      <td>3.91</td>\n",
       "      <td>3.90</td>\n",
       "      <td>3.91</td>\n",
       "      <td>3.87</td>\n",
       "      <td>119,76M</td>\n",
       "      <td>0,77%</td>\n",
       "      <td>2025-05-07</td>\n",
       "      <td>-0.220537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2025-05-06</td>\n",
       "      <td>3.88</td>\n",
       "      <td>3.84</td>\n",
       "      <td>3.90</td>\n",
       "      <td>3.84</td>\n",
       "      <td>111,33M</td>\n",
       "      <td>0,52%</td>\n",
       "      <td>2025-05-06</td>\n",
       "      <td>-0.010816</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2025-05-05</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.90</td>\n",
       "      <td>3.92</td>\n",
       "      <td>3.86</td>\n",
       "      <td>196,92M</td>\n",
       "      <td>-0,52%</td>\n",
       "      <td>2025-05-05</td>\n",
       "      <td>0.180110</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2025-05-02</td>\n",
       "      <td>3.88</td>\n",
       "      <td>3.92</td>\n",
       "      <td>3.92</td>\n",
       "      <td>3.85</td>\n",
       "      <td>205,63M</td>\n",
       "      <td>0,78%</td>\n",
       "      <td>2025-05-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Tanggal  Terakhir  Pembukaan  Tertinggi  Terendah     Vol. Perubahan%  \\\n",
       "0   2025-07-04      3.67       3.68       3.71      3.65   91,14M     -0,27%   \n",
       "1   2025-07-03      3.68       3.71       3.73      3.68  119,67M      0,00%   \n",
       "2   2025-07-02      3.68       3.65       3.70      3.64  220,27M     -0,54%   \n",
       "3   2025-07-01      3.70       3.78       3.79      3.67  212,37M     -1,07%   \n",
       "4   2025-06-30      3.74       3.84       3.84      3.73  271,93M     -2,35%   \n",
       "5   2025-06-26      3.83       3.78       3.83      3.75  171,43M      1,86%   \n",
       "6   2025-06-25      3.76       3.83       3.83      3.73  164,26M     -0,53%   \n",
       "7   2025-06-24      3.78       3.82       3.90      3.77  281,59M      1,61%   \n",
       "8   2025-06-23      3.72       3.73       3.75      3.66  222,07M     -1,85%   \n",
       "9   2025-06-20      3.79       3.74       3.84      3.74  516,18M     -0,26%   \n",
       "10  2025-06-19      3.80       3.90       3.92      3.80  355,41M     -3,55%   \n",
       "11  2025-06-18      3.94       3.95       3.96      3.90  140,88M     -0,51%   \n",
       "12  2025-06-17      3.96       4.01       4.03      3.96  125,77M     -0,75%   \n",
       "13  2025-06-16      3.99       3.98       4.01      3.96  155,45M     -0,25%   \n",
       "14  2025-06-13      4.00       4.02       4.05      3.98  283,83M     -1,72%   \n",
       "15  2025-06-12      4.07       4.07       4.10      4.06  113,85M      0,00%   \n",
       "16  2025-06-11      4.07       4.13       4.14      4.06  196,56M     -1,93%   \n",
       "17  2025-06-10      4.15       4.10       4.16      4.10  179,83M      1,22%   \n",
       "18  2025-06-05      4.10       4.11       4.14      4.05  230,13M      0,49%   \n",
       "19  2025-06-04      4.08       4.23       4.23      4.08  279,76M     -2,86%   \n",
       "20  2025-06-03      4.20       4.21       4.23      4.12  277,90M      0,00%   \n",
       "21  2025-06-02      4.20       4.36       4.39      4.20  389,54M     -5,62%   \n",
       "22  2025-05-28      4.45       4.36       4.45      4.32  466,13M      1,83%   \n",
       "23  2025-05-27      4.37       4.32       4.37      4.28  180,03M      1,16%   \n",
       "24  2025-05-26      4.32       4.35       4.35      4.26  149,42M     -0,69%   \n",
       "25  2025-05-23      4.35       4.37       4.37      4.33  187,46M      1,16%   \n",
       "26  2025-05-22      4.30       4.28       4.31      4.24  208,29M      0,94%   \n",
       "27  2025-05-21      4.26       4.21       4.31      4.21  256,02M      1,19%   \n",
       "28  2025-05-20      4.21       4.23       4.28      4.17  209,58M     -0,47%   \n",
       "29  2025-05-19      4.23       4.23       4.26      4.20  145,94M     -0,47%   \n",
       "30  2025-05-16      4.25       4.31       4.33      4.16  289,34M     -0,47%   \n",
       "31  2025-05-15      4.27       4.14       4.31      4.13  537,15M      4,40%   \n",
       "32  2025-05-14      4.09       4.00       4.09      3.96  461,64M      6,51%   \n",
       "33  2025-05-09      3.84       3.81       3.84      3.76  147,64M      1,32%   \n",
       "34  2025-05-08      3.79       3.91       3.96      3.78  224,12M     -3,07%   \n",
       "35  2025-05-07      3.91       3.90       3.91      3.87  119,76M      0,77%   \n",
       "36  2025-05-06      3.88       3.84       3.90      3.84  111,33M      0,52%   \n",
       "37  2025-05-05      3.86       3.90       3.92      3.86  196,92M     -0,52%   \n",
       "38  2025-05-02      3.88       3.92       3.92      3.85  205,63M      0,78%   \n",
       "\n",
       "          date  avg_signed_sentiment  count_positive  count_negative  \\\n",
       "0   2025-07-04             -0.000960             4.0             3.0   \n",
       "1   2025-07-03              0.052033             5.0             3.0   \n",
       "2   2025-07-02             -0.007767             2.0             2.0   \n",
       "3   2025-07-01             -0.018503             4.0             4.0   \n",
       "4   2025-06-30             -0.124553             0.0             2.0   \n",
       "5   2025-06-26              0.198789             1.0             0.0   \n",
       "6   2025-06-25             -0.072154             0.0             1.0   \n",
       "7   2025-06-24              0.000000             0.0             0.0   \n",
       "8   2025-06-23             -0.374837             0.0             6.0   \n",
       "9   2025-06-20             -0.111262             2.0             3.0   \n",
       "10  2025-06-19             -0.155275             2.0             7.0   \n",
       "11  2025-06-18             -0.138931             4.0             8.0   \n",
       "12  2025-06-17              0.047399             3.0             2.0   \n",
       "13  2025-06-16             -0.126163             1.0             3.0   \n",
       "14  2025-06-13              0.163476             4.0             1.0   \n",
       "15  2025-06-12              0.046693             1.0             1.0   \n",
       "16  2025-06-11              0.037650             3.0             1.0   \n",
       "17  2025-06-10             -0.054510             1.0             1.0   \n",
       "18  2025-06-05              0.179834             3.0             0.0   \n",
       "19  2025-06-04              0.000000             0.0             0.0   \n",
       "20  2025-06-03             -0.014521             8.0             8.0   \n",
       "21  2025-06-02             -0.114793             5.0            10.0   \n",
       "22  2025-05-28             -0.198505             2.0             6.0   \n",
       "23  2025-05-27              0.302433             3.0             0.0   \n",
       "24  2025-05-26             -0.128274             1.0             3.0   \n",
       "25  2025-05-23             -0.020540             4.0             4.0   \n",
       "26  2025-05-22              0.045951             3.0             2.0   \n",
       "27  2025-05-21             -0.153046             0.0             3.0   \n",
       "28  2025-05-20              0.048572             4.0             3.0   \n",
       "29  2025-05-19              0.331064            10.0             1.0   \n",
       "30  2025-05-16             -0.176841             3.0             7.0   \n",
       "31  2025-05-15              0.075178            18.0            12.0   \n",
       "32  2025-05-14             -0.085922             1.0             5.0   \n",
       "33  2025-05-09              0.000000             0.0             0.0   \n",
       "34  2025-05-08             -0.209798             0.0             3.0   \n",
       "35  2025-05-07             -0.220537             0.0             2.0   \n",
       "36  2025-05-06             -0.010816             1.0             1.0   \n",
       "37  2025-05-05              0.180110             5.0             0.0   \n",
       "38  2025-05-02                   NaN             NaN             NaN   \n",
       "\n",
       "    count_neutral  total_tweets  \n",
       "0            54.0          61.0  \n",
       "1            21.0          29.0  \n",
       "2            16.0          20.0  \n",
       "3            16.0          24.0  \n",
       "4            12.0          14.0  \n",
       "5             4.0           5.0  \n",
       "6            11.0          12.0  \n",
       "7            15.0          15.0  \n",
       "8             8.0          14.0  \n",
       "9            10.0          15.0  \n",
       "10           18.0          27.0  \n",
       "11           21.0          33.0  \n",
       "12           13.0          18.0  \n",
       "13            9.0          13.0  \n",
       "14           10.0          15.0  \n",
       "15            6.0           8.0  \n",
       "16           21.0          25.0  \n",
       "17            3.0           5.0  \n",
       "18           12.0          15.0  \n",
       "19           17.0          17.0  \n",
       "20           19.0          35.0  \n",
       "21           24.0          39.0  \n",
       "22           12.0          20.0  \n",
       "23            6.0           9.0  \n",
       "24            7.0          11.0  \n",
       "25           12.0          20.0  \n",
       "26           12.0          17.0  \n",
       "27           14.0          17.0  \n",
       "28           10.0          17.0  \n",
       "29           13.0          24.0  \n",
       "30           17.0          27.0  \n",
       "31           40.0          70.0  \n",
       "32           32.0          38.0  \n",
       "33            5.0           5.0  \n",
       "34           11.0          14.0  \n",
       "35            4.0           6.0  \n",
       "36           15.0          17.0  \n",
       "37           21.0          26.0  \n",
       "38            NaN           NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_default = pd.read_csv('../data/processed/dataset_model.csv')\n",
    "df_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 141,
     "status": "ok",
     "timestamp": 1752996559004,
     "user": {
      "displayName": "azka nuril",
      "userId": "09044520640447098125"
     },
     "user_tz": -420
    },
    "id": "5I7dzLX5Q_ME",
    "outputId": "0ea1e63b-bdbb-4358-d8be-9d0926ea5d27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39 entries, 0 to 38\n",
      "Data columns (total 13 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Tanggal               39 non-null     object \n",
      " 1   Terakhir              39 non-null     float64\n",
      " 2   Pembukaan             39 non-null     float64\n",
      " 3   Tertinggi             39 non-null     float64\n",
      " 4   Terendah              39 non-null     float64\n",
      " 5   Vol.                  39 non-null     object \n",
      " 6   Perubahan%            39 non-null     object \n",
      " 7   date                  39 non-null     object \n",
      " 8   avg_signed_sentiment  38 non-null     float64\n",
      " 9   count_positive        38 non-null     float64\n",
      " 10  count_negative        38 non-null     float64\n",
      " 11  count_neutral         38 non-null     float64\n",
      " 12  total_tweets          38 non-null     float64\n",
      "dtypes: float64(9), object(4)\n",
      "memory usage: 4.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_default.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1752996559010,
     "user": {
      "displayName": "azka nuril",
      "userId": "09044520640447098125"
     },
     "user_tz": -420
    },
    "id": "H6wPtORbRQRc"
   },
   "outputs": [],
   "source": [
    "df_default.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 166,
     "status": "ok",
     "timestamp": 1752996559180,
     "user": {
      "displayName": "azka nuril",
      "userId": "09044520640447098125"
     },
     "user_tz": -420
    },
    "id": "vLqYmKQMRlK1",
    "outputId": "e39726e9-087e-484d-d297-096c286f9de0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tanggal</th>\n",
       "      <th>Terakhir</th>\n",
       "      <th>Pembukaan</th>\n",
       "      <th>Tertinggi</th>\n",
       "      <th>Terendah</th>\n",
       "      <th>Vol.</th>\n",
       "      <th>Perubahan%</th>\n",
       "      <th>avg_signed_sentiment</th>\n",
       "      <th>count_positive</th>\n",
       "      <th>count_negative</th>\n",
       "      <th>count_neutral</th>\n",
       "      <th>total_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-07-04</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.68</td>\n",
       "      <td>3.71</td>\n",
       "      <td>3.65</td>\n",
       "      <td>91,14M</td>\n",
       "      <td>-0,27%</td>\n",
       "      <td>-0.000960</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-07-03</td>\n",
       "      <td>3.68</td>\n",
       "      <td>3.71</td>\n",
       "      <td>3.73</td>\n",
       "      <td>3.68</td>\n",
       "      <td>119,67M</td>\n",
       "      <td>0,00%</td>\n",
       "      <td>0.052033</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-07-02</td>\n",
       "      <td>3.68</td>\n",
       "      <td>3.65</td>\n",
       "      <td>3.70</td>\n",
       "      <td>3.64</td>\n",
       "      <td>220,27M</td>\n",
       "      <td>-0,54%</td>\n",
       "      <td>-0.007767</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>3.70</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.67</td>\n",
       "      <td>212,37M</td>\n",
       "      <td>-1,07%</td>\n",
       "      <td>-0.018503</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>3.74</td>\n",
       "      <td>3.84</td>\n",
       "      <td>3.84</td>\n",
       "      <td>3.73</td>\n",
       "      <td>271,93M</td>\n",
       "      <td>-2,35%</td>\n",
       "      <td>-0.124553</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-06-26</td>\n",
       "      <td>3.83</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.83</td>\n",
       "      <td>3.75</td>\n",
       "      <td>171,43M</td>\n",
       "      <td>1,86%</td>\n",
       "      <td>0.198789</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-06-25</td>\n",
       "      <td>3.76</td>\n",
       "      <td>3.83</td>\n",
       "      <td>3.83</td>\n",
       "      <td>3.73</td>\n",
       "      <td>164,26M</td>\n",
       "      <td>-0,53%</td>\n",
       "      <td>-0.072154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-06-24</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.82</td>\n",
       "      <td>3.90</td>\n",
       "      <td>3.77</td>\n",
       "      <td>281,59M</td>\n",
       "      <td>1,61%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-06-23</td>\n",
       "      <td>3.72</td>\n",
       "      <td>3.73</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.66</td>\n",
       "      <td>222,07M</td>\n",
       "      <td>-1,85%</td>\n",
       "      <td>-0.374837</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2025-06-20</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.74</td>\n",
       "      <td>3.84</td>\n",
       "      <td>3.74</td>\n",
       "      <td>516,18M</td>\n",
       "      <td>-0,26%</td>\n",
       "      <td>-0.111262</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2025-06-19</td>\n",
       "      <td>3.80</td>\n",
       "      <td>3.90</td>\n",
       "      <td>3.92</td>\n",
       "      <td>3.80</td>\n",
       "      <td>355,41M</td>\n",
       "      <td>-3,55%</td>\n",
       "      <td>-0.155275</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2025-06-18</td>\n",
       "      <td>3.94</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.96</td>\n",
       "      <td>3.90</td>\n",
       "      <td>140,88M</td>\n",
       "      <td>-0,51%</td>\n",
       "      <td>-0.138931</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2025-06-17</td>\n",
       "      <td>3.96</td>\n",
       "      <td>4.01</td>\n",
       "      <td>4.03</td>\n",
       "      <td>3.96</td>\n",
       "      <td>125,77M</td>\n",
       "      <td>-0,75%</td>\n",
       "      <td>0.047399</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2025-06-16</td>\n",
       "      <td>3.99</td>\n",
       "      <td>3.98</td>\n",
       "      <td>4.01</td>\n",
       "      <td>3.96</td>\n",
       "      <td>155,45M</td>\n",
       "      <td>-0,25%</td>\n",
       "      <td>-0.126163</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2025-06-13</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.02</td>\n",
       "      <td>4.05</td>\n",
       "      <td>3.98</td>\n",
       "      <td>283,83M</td>\n",
       "      <td>-1,72%</td>\n",
       "      <td>0.163476</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2025-06-12</td>\n",
       "      <td>4.07</td>\n",
       "      <td>4.07</td>\n",
       "      <td>4.10</td>\n",
       "      <td>4.06</td>\n",
       "      <td>113,85M</td>\n",
       "      <td>0,00%</td>\n",
       "      <td>0.046693</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2025-06-11</td>\n",
       "      <td>4.07</td>\n",
       "      <td>4.13</td>\n",
       "      <td>4.14</td>\n",
       "      <td>4.06</td>\n",
       "      <td>196,56M</td>\n",
       "      <td>-1,93%</td>\n",
       "      <td>0.037650</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2025-06-10</td>\n",
       "      <td>4.15</td>\n",
       "      <td>4.10</td>\n",
       "      <td>4.16</td>\n",
       "      <td>4.10</td>\n",
       "      <td>179,83M</td>\n",
       "      <td>1,22%</td>\n",
       "      <td>-0.054510</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2025-06-05</td>\n",
       "      <td>4.10</td>\n",
       "      <td>4.11</td>\n",
       "      <td>4.14</td>\n",
       "      <td>4.05</td>\n",
       "      <td>230,13M</td>\n",
       "      <td>0,49%</td>\n",
       "      <td>0.179834</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2025-06-04</td>\n",
       "      <td>4.08</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.08</td>\n",
       "      <td>279,76M</td>\n",
       "      <td>-2,86%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2025-06-03</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.21</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.12</td>\n",
       "      <td>277,90M</td>\n",
       "      <td>0,00%</td>\n",
       "      <td>-0.014521</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2025-06-02</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.36</td>\n",
       "      <td>4.39</td>\n",
       "      <td>4.20</td>\n",
       "      <td>389,54M</td>\n",
       "      <td>-5,62%</td>\n",
       "      <td>-0.114793</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2025-05-28</td>\n",
       "      <td>4.45</td>\n",
       "      <td>4.36</td>\n",
       "      <td>4.45</td>\n",
       "      <td>4.32</td>\n",
       "      <td>466,13M</td>\n",
       "      <td>1,83%</td>\n",
       "      <td>-0.198505</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2025-05-27</td>\n",
       "      <td>4.37</td>\n",
       "      <td>4.32</td>\n",
       "      <td>4.37</td>\n",
       "      <td>4.28</td>\n",
       "      <td>180,03M</td>\n",
       "      <td>1,16%</td>\n",
       "      <td>0.302433</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2025-05-26</td>\n",
       "      <td>4.32</td>\n",
       "      <td>4.35</td>\n",
       "      <td>4.35</td>\n",
       "      <td>4.26</td>\n",
       "      <td>149,42M</td>\n",
       "      <td>-0,69%</td>\n",
       "      <td>-0.128274</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2025-05-23</td>\n",
       "      <td>4.35</td>\n",
       "      <td>4.37</td>\n",
       "      <td>4.37</td>\n",
       "      <td>4.33</td>\n",
       "      <td>187,46M</td>\n",
       "      <td>1,16%</td>\n",
       "      <td>-0.020540</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2025-05-22</td>\n",
       "      <td>4.30</td>\n",
       "      <td>4.28</td>\n",
       "      <td>4.31</td>\n",
       "      <td>4.24</td>\n",
       "      <td>208,29M</td>\n",
       "      <td>0,94%</td>\n",
       "      <td>0.045951</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2025-05-21</td>\n",
       "      <td>4.26</td>\n",
       "      <td>4.21</td>\n",
       "      <td>4.31</td>\n",
       "      <td>4.21</td>\n",
       "      <td>256,02M</td>\n",
       "      <td>1,19%</td>\n",
       "      <td>-0.153046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2025-05-20</td>\n",
       "      <td>4.21</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.28</td>\n",
       "      <td>4.17</td>\n",
       "      <td>209,58M</td>\n",
       "      <td>-0,47%</td>\n",
       "      <td>0.048572</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2025-05-19</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.26</td>\n",
       "      <td>4.20</td>\n",
       "      <td>145,94M</td>\n",
       "      <td>-0,47%</td>\n",
       "      <td>0.331064</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2025-05-16</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.31</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.16</td>\n",
       "      <td>289,34M</td>\n",
       "      <td>-0,47%</td>\n",
       "      <td>-0.176841</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2025-05-15</td>\n",
       "      <td>4.27</td>\n",
       "      <td>4.14</td>\n",
       "      <td>4.31</td>\n",
       "      <td>4.13</td>\n",
       "      <td>537,15M</td>\n",
       "      <td>4,40%</td>\n",
       "      <td>0.075178</td>\n",
       "      <td>18.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2025-05-14</td>\n",
       "      <td>4.09</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.09</td>\n",
       "      <td>3.96</td>\n",
       "      <td>461,64M</td>\n",
       "      <td>6,51%</td>\n",
       "      <td>-0.085922</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2025-05-09</td>\n",
       "      <td>3.84</td>\n",
       "      <td>3.81</td>\n",
       "      <td>3.84</td>\n",
       "      <td>3.76</td>\n",
       "      <td>147,64M</td>\n",
       "      <td>1,32%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2025-05-08</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.91</td>\n",
       "      <td>3.96</td>\n",
       "      <td>3.78</td>\n",
       "      <td>224,12M</td>\n",
       "      <td>-3,07%</td>\n",
       "      <td>-0.209798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2025-05-07</td>\n",
       "      <td>3.91</td>\n",
       "      <td>3.90</td>\n",
       "      <td>3.91</td>\n",
       "      <td>3.87</td>\n",
       "      <td>119,76M</td>\n",
       "      <td>0,77%</td>\n",
       "      <td>-0.220537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2025-05-06</td>\n",
       "      <td>3.88</td>\n",
       "      <td>3.84</td>\n",
       "      <td>3.90</td>\n",
       "      <td>3.84</td>\n",
       "      <td>111,33M</td>\n",
       "      <td>0,52%</td>\n",
       "      <td>-0.010816</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2025-05-05</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.90</td>\n",
       "      <td>3.92</td>\n",
       "      <td>3.86</td>\n",
       "      <td>196,92M</td>\n",
       "      <td>-0,52%</td>\n",
       "      <td>0.180110</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Tanggal  Terakhir  Pembukaan  Tertinggi  Terendah     Vol. Perubahan%  \\\n",
       "0   2025-07-04      3.67       3.68       3.71      3.65   91,14M     -0,27%   \n",
       "1   2025-07-03      3.68       3.71       3.73      3.68  119,67M      0,00%   \n",
       "2   2025-07-02      3.68       3.65       3.70      3.64  220,27M     -0,54%   \n",
       "3   2025-07-01      3.70       3.78       3.79      3.67  212,37M     -1,07%   \n",
       "4   2025-06-30      3.74       3.84       3.84      3.73  271,93M     -2,35%   \n",
       "5   2025-06-26      3.83       3.78       3.83      3.75  171,43M      1,86%   \n",
       "6   2025-06-25      3.76       3.83       3.83      3.73  164,26M     -0,53%   \n",
       "7   2025-06-24      3.78       3.82       3.90      3.77  281,59M      1,61%   \n",
       "8   2025-06-23      3.72       3.73       3.75      3.66  222,07M     -1,85%   \n",
       "9   2025-06-20      3.79       3.74       3.84      3.74  516,18M     -0,26%   \n",
       "10  2025-06-19      3.80       3.90       3.92      3.80  355,41M     -3,55%   \n",
       "11  2025-06-18      3.94       3.95       3.96      3.90  140,88M     -0,51%   \n",
       "12  2025-06-17      3.96       4.01       4.03      3.96  125,77M     -0,75%   \n",
       "13  2025-06-16      3.99       3.98       4.01      3.96  155,45M     -0,25%   \n",
       "14  2025-06-13      4.00       4.02       4.05      3.98  283,83M     -1,72%   \n",
       "15  2025-06-12      4.07       4.07       4.10      4.06  113,85M      0,00%   \n",
       "16  2025-06-11      4.07       4.13       4.14      4.06  196,56M     -1,93%   \n",
       "17  2025-06-10      4.15       4.10       4.16      4.10  179,83M      1,22%   \n",
       "18  2025-06-05      4.10       4.11       4.14      4.05  230,13M      0,49%   \n",
       "19  2025-06-04      4.08       4.23       4.23      4.08  279,76M     -2,86%   \n",
       "20  2025-06-03      4.20       4.21       4.23      4.12  277,90M      0,00%   \n",
       "21  2025-06-02      4.20       4.36       4.39      4.20  389,54M     -5,62%   \n",
       "22  2025-05-28      4.45       4.36       4.45      4.32  466,13M      1,83%   \n",
       "23  2025-05-27      4.37       4.32       4.37      4.28  180,03M      1,16%   \n",
       "24  2025-05-26      4.32       4.35       4.35      4.26  149,42M     -0,69%   \n",
       "25  2025-05-23      4.35       4.37       4.37      4.33  187,46M      1,16%   \n",
       "26  2025-05-22      4.30       4.28       4.31      4.24  208,29M      0,94%   \n",
       "27  2025-05-21      4.26       4.21       4.31      4.21  256,02M      1,19%   \n",
       "28  2025-05-20      4.21       4.23       4.28      4.17  209,58M     -0,47%   \n",
       "29  2025-05-19      4.23       4.23       4.26      4.20  145,94M     -0,47%   \n",
       "30  2025-05-16      4.25       4.31       4.33      4.16  289,34M     -0,47%   \n",
       "31  2025-05-15      4.27       4.14       4.31      4.13  537,15M      4,40%   \n",
       "32  2025-05-14      4.09       4.00       4.09      3.96  461,64M      6,51%   \n",
       "33  2025-05-09      3.84       3.81       3.84      3.76  147,64M      1,32%   \n",
       "34  2025-05-08      3.79       3.91       3.96      3.78  224,12M     -3,07%   \n",
       "35  2025-05-07      3.91       3.90       3.91      3.87  119,76M      0,77%   \n",
       "36  2025-05-06      3.88       3.84       3.90      3.84  111,33M      0,52%   \n",
       "37  2025-05-05      3.86       3.90       3.92      3.86  196,92M     -0,52%   \n",
       "\n",
       "    avg_signed_sentiment  count_positive  count_negative  count_neutral  \\\n",
       "0              -0.000960             4.0             3.0           54.0   \n",
       "1               0.052033             5.0             3.0           21.0   \n",
       "2              -0.007767             2.0             2.0           16.0   \n",
       "3              -0.018503             4.0             4.0           16.0   \n",
       "4              -0.124553             0.0             2.0           12.0   \n",
       "5               0.198789             1.0             0.0            4.0   \n",
       "6              -0.072154             0.0             1.0           11.0   \n",
       "7               0.000000             0.0             0.0           15.0   \n",
       "8              -0.374837             0.0             6.0            8.0   \n",
       "9              -0.111262             2.0             3.0           10.0   \n",
       "10             -0.155275             2.0             7.0           18.0   \n",
       "11             -0.138931             4.0             8.0           21.0   \n",
       "12              0.047399             3.0             2.0           13.0   \n",
       "13             -0.126163             1.0             3.0            9.0   \n",
       "14              0.163476             4.0             1.0           10.0   \n",
       "15              0.046693             1.0             1.0            6.0   \n",
       "16              0.037650             3.0             1.0           21.0   \n",
       "17             -0.054510             1.0             1.0            3.0   \n",
       "18              0.179834             3.0             0.0           12.0   \n",
       "19              0.000000             0.0             0.0           17.0   \n",
       "20             -0.014521             8.0             8.0           19.0   \n",
       "21             -0.114793             5.0            10.0           24.0   \n",
       "22             -0.198505             2.0             6.0           12.0   \n",
       "23              0.302433             3.0             0.0            6.0   \n",
       "24             -0.128274             1.0             3.0            7.0   \n",
       "25             -0.020540             4.0             4.0           12.0   \n",
       "26              0.045951             3.0             2.0           12.0   \n",
       "27             -0.153046             0.0             3.0           14.0   \n",
       "28              0.048572             4.0             3.0           10.0   \n",
       "29              0.331064            10.0             1.0           13.0   \n",
       "30             -0.176841             3.0             7.0           17.0   \n",
       "31              0.075178            18.0            12.0           40.0   \n",
       "32             -0.085922             1.0             5.0           32.0   \n",
       "33              0.000000             0.0             0.0            5.0   \n",
       "34             -0.209798             0.0             3.0           11.0   \n",
       "35             -0.220537             0.0             2.0            4.0   \n",
       "36             -0.010816             1.0             1.0           15.0   \n",
       "37              0.180110             5.0             0.0           21.0   \n",
       "\n",
       "    total_tweets  \n",
       "0           61.0  \n",
       "1           29.0  \n",
       "2           20.0  \n",
       "3           24.0  \n",
       "4           14.0  \n",
       "5            5.0  \n",
       "6           12.0  \n",
       "7           15.0  \n",
       "8           14.0  \n",
       "9           15.0  \n",
       "10          27.0  \n",
       "11          33.0  \n",
       "12          18.0  \n",
       "13          13.0  \n",
       "14          15.0  \n",
       "15           8.0  \n",
       "16          25.0  \n",
       "17           5.0  \n",
       "18          15.0  \n",
       "19          17.0  \n",
       "20          35.0  \n",
       "21          39.0  \n",
       "22          20.0  \n",
       "23           9.0  \n",
       "24          11.0  \n",
       "25          20.0  \n",
       "26          17.0  \n",
       "27          17.0  \n",
       "28          17.0  \n",
       "29          24.0  \n",
       "30          27.0  \n",
       "31          70.0  \n",
       "32          38.0  \n",
       "33           5.0  \n",
       "34          14.0  \n",
       "35           6.0  \n",
       "36          17.0  \n",
       "37          26.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_default.drop(columns=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1752996559188,
     "user": {
      "displayName": "azka nuril",
      "userId": "09044520640447098125"
     },
     "user_tz": -420
    },
    "id": "YImdNirOQ7Nw"
   },
   "outputs": [],
   "source": [
    "df_default['Tanggal'] = pd.to_datetime(df_default['Tanggal'])\n",
    "df_default.sort_values(by='Tanggal', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1752996559199,
     "user": {
      "displayName": "azka nuril",
      "userId": "09044520640447098125"
     },
     "user_tz": -420
    },
    "id": "ljJjxNLDRvCj"
   },
   "outputs": [],
   "source": [
    "def parse_volume(vol_str):\n",
    "    if isinstance(vol_str, str):\n",
    "        vol_str = vol_str.replace(',', '.')\n",
    "        if vol_str.endswith('M'):\n",
    "            return float(vol_str[:-1]) * 1_000_000\n",
    "        elif vol_str.endswith('K'):\n",
    "            return float(vol_str[:-1]) * 1_000\n",
    "        else:\n",
    "            return float(vol_str)\n",
    "    return vol_str\n",
    "\n",
    "df_default['Vol.'] = df_default['Vol.'].apply(parse_volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1752996559210,
     "user": {
      "displayName": "azka nuril",
      "userId": "09044520640447098125"
     },
     "user_tz": -420
    },
    "id": "DrgU1bPkU1jV"
   },
   "outputs": [],
   "source": [
    "df_default['Perubahan%'] = df_default['Perubahan%'].str.replace('%', '', regex=False)\n",
    "df_default['Perubahan%'] = df_default['Perubahan%'].str.replace(',', '.', regex=False).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 133,
     "status": "ok",
     "timestamp": 1752996559347,
     "user": {
      "displayName": "azka nuril",
      "userId": "09044520640447098125"
     },
     "user_tz": -420
    },
    "id": "4S2kbMeXR8Wk",
    "outputId": "c16f62e9-a654-4d15-9e6e-2c040b24e17c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tanggal</th>\n",
       "      <th>Terakhir</th>\n",
       "      <th>Pembukaan</th>\n",
       "      <th>Tertinggi</th>\n",
       "      <th>Terendah</th>\n",
       "      <th>Vol.</th>\n",
       "      <th>Perubahan%</th>\n",
       "      <th>date</th>\n",
       "      <th>avg_signed_sentiment</th>\n",
       "      <th>count_positive</th>\n",
       "      <th>count_negative</th>\n",
       "      <th>count_neutral</th>\n",
       "      <th>total_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2025-05-05</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.90</td>\n",
       "      <td>3.92</td>\n",
       "      <td>3.86</td>\n",
       "      <td>196920000.0</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>2025-05-05</td>\n",
       "      <td>0.180110</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2025-05-06</td>\n",
       "      <td>3.88</td>\n",
       "      <td>3.84</td>\n",
       "      <td>3.90</td>\n",
       "      <td>3.84</td>\n",
       "      <td>111330000.0</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2025-05-06</td>\n",
       "      <td>-0.010816</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2025-05-07</td>\n",
       "      <td>3.91</td>\n",
       "      <td>3.90</td>\n",
       "      <td>3.91</td>\n",
       "      <td>3.87</td>\n",
       "      <td>119760000.0</td>\n",
       "      <td>0.77</td>\n",
       "      <td>2025-05-07</td>\n",
       "      <td>-0.220537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2025-05-08</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.91</td>\n",
       "      <td>3.96</td>\n",
       "      <td>3.78</td>\n",
       "      <td>224120000.0</td>\n",
       "      <td>-3.07</td>\n",
       "      <td>2025-05-08</td>\n",
       "      <td>-0.209798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2025-05-09</td>\n",
       "      <td>3.84</td>\n",
       "      <td>3.81</td>\n",
       "      <td>3.84</td>\n",
       "      <td>3.76</td>\n",
       "      <td>147640000.0</td>\n",
       "      <td>1.32</td>\n",
       "      <td>2025-05-09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2025-05-14</td>\n",
       "      <td>4.09</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.09</td>\n",
       "      <td>3.96</td>\n",
       "      <td>461640000.0</td>\n",
       "      <td>6.51</td>\n",
       "      <td>2025-05-14</td>\n",
       "      <td>-0.085922</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2025-05-15</td>\n",
       "      <td>4.27</td>\n",
       "      <td>4.14</td>\n",
       "      <td>4.31</td>\n",
       "      <td>4.13</td>\n",
       "      <td>537150000.0</td>\n",
       "      <td>4.40</td>\n",
       "      <td>2025-05-15</td>\n",
       "      <td>0.075178</td>\n",
       "      <td>18.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2025-05-16</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.31</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.16</td>\n",
       "      <td>289340000.0</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>2025-05-16</td>\n",
       "      <td>-0.176841</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2025-05-19</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.26</td>\n",
       "      <td>4.20</td>\n",
       "      <td>145940000.0</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>2025-05-19</td>\n",
       "      <td>0.331064</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2025-05-20</td>\n",
       "      <td>4.21</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.28</td>\n",
       "      <td>4.17</td>\n",
       "      <td>209580000.0</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>2025-05-20</td>\n",
       "      <td>0.048572</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2025-05-21</td>\n",
       "      <td>4.26</td>\n",
       "      <td>4.21</td>\n",
       "      <td>4.31</td>\n",
       "      <td>4.21</td>\n",
       "      <td>256020000.0</td>\n",
       "      <td>1.19</td>\n",
       "      <td>2025-05-21</td>\n",
       "      <td>-0.153046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2025-05-22</td>\n",
       "      <td>4.30</td>\n",
       "      <td>4.28</td>\n",
       "      <td>4.31</td>\n",
       "      <td>4.24</td>\n",
       "      <td>208290000.0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>2025-05-22</td>\n",
       "      <td>0.045951</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2025-05-23</td>\n",
       "      <td>4.35</td>\n",
       "      <td>4.37</td>\n",
       "      <td>4.37</td>\n",
       "      <td>4.33</td>\n",
       "      <td>187460000.0</td>\n",
       "      <td>1.16</td>\n",
       "      <td>2025-05-23</td>\n",
       "      <td>-0.020540</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2025-05-26</td>\n",
       "      <td>4.32</td>\n",
       "      <td>4.35</td>\n",
       "      <td>4.35</td>\n",
       "      <td>4.26</td>\n",
       "      <td>149420000.0</td>\n",
       "      <td>-0.69</td>\n",
       "      <td>2025-05-26</td>\n",
       "      <td>-0.128274</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2025-05-27</td>\n",
       "      <td>4.37</td>\n",
       "      <td>4.32</td>\n",
       "      <td>4.37</td>\n",
       "      <td>4.28</td>\n",
       "      <td>180030000.0</td>\n",
       "      <td>1.16</td>\n",
       "      <td>2025-05-27</td>\n",
       "      <td>0.302433</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2025-05-28</td>\n",
       "      <td>4.45</td>\n",
       "      <td>4.36</td>\n",
       "      <td>4.45</td>\n",
       "      <td>4.32</td>\n",
       "      <td>466130000.0</td>\n",
       "      <td>1.83</td>\n",
       "      <td>2025-05-28</td>\n",
       "      <td>-0.198505</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2025-06-02</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.36</td>\n",
       "      <td>4.39</td>\n",
       "      <td>4.20</td>\n",
       "      <td>389540000.0</td>\n",
       "      <td>-5.62</td>\n",
       "      <td>2025-06-02</td>\n",
       "      <td>-0.114793</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2025-06-03</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.21</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.12</td>\n",
       "      <td>277900000.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2025-06-03</td>\n",
       "      <td>-0.014521</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2025-06-04</td>\n",
       "      <td>4.08</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.08</td>\n",
       "      <td>279760000.0</td>\n",
       "      <td>-2.86</td>\n",
       "      <td>2025-06-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2025-06-05</td>\n",
       "      <td>4.10</td>\n",
       "      <td>4.11</td>\n",
       "      <td>4.14</td>\n",
       "      <td>4.05</td>\n",
       "      <td>230130000.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>2025-06-05</td>\n",
       "      <td>0.179834</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2025-06-10</td>\n",
       "      <td>4.15</td>\n",
       "      <td>4.10</td>\n",
       "      <td>4.16</td>\n",
       "      <td>4.10</td>\n",
       "      <td>179830000.0</td>\n",
       "      <td>1.22</td>\n",
       "      <td>2025-06-10</td>\n",
       "      <td>-0.054510</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2025-06-11</td>\n",
       "      <td>4.07</td>\n",
       "      <td>4.13</td>\n",
       "      <td>4.14</td>\n",
       "      <td>4.06</td>\n",
       "      <td>196560000.0</td>\n",
       "      <td>-1.93</td>\n",
       "      <td>2025-06-11</td>\n",
       "      <td>0.037650</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2025-06-12</td>\n",
       "      <td>4.07</td>\n",
       "      <td>4.07</td>\n",
       "      <td>4.10</td>\n",
       "      <td>4.06</td>\n",
       "      <td>113850000.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2025-06-12</td>\n",
       "      <td>0.046693</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2025-06-13</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.02</td>\n",
       "      <td>4.05</td>\n",
       "      <td>3.98</td>\n",
       "      <td>283830000.0</td>\n",
       "      <td>-1.72</td>\n",
       "      <td>2025-06-13</td>\n",
       "      <td>0.163476</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2025-06-16</td>\n",
       "      <td>3.99</td>\n",
       "      <td>3.98</td>\n",
       "      <td>4.01</td>\n",
       "      <td>3.96</td>\n",
       "      <td>155450000.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>2025-06-16</td>\n",
       "      <td>-0.126163</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2025-06-17</td>\n",
       "      <td>3.96</td>\n",
       "      <td>4.01</td>\n",
       "      <td>4.03</td>\n",
       "      <td>3.96</td>\n",
       "      <td>125770000.0</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>2025-06-17</td>\n",
       "      <td>0.047399</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2025-06-18</td>\n",
       "      <td>3.94</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.96</td>\n",
       "      <td>3.90</td>\n",
       "      <td>140880000.0</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>2025-06-18</td>\n",
       "      <td>-0.138931</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2025-06-19</td>\n",
       "      <td>3.80</td>\n",
       "      <td>3.90</td>\n",
       "      <td>3.92</td>\n",
       "      <td>3.80</td>\n",
       "      <td>355410000.0</td>\n",
       "      <td>-3.55</td>\n",
       "      <td>2025-06-19</td>\n",
       "      <td>-0.155275</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2025-06-20</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.74</td>\n",
       "      <td>3.84</td>\n",
       "      <td>3.74</td>\n",
       "      <td>516180000.0</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>2025-06-20</td>\n",
       "      <td>-0.111262</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-06-23</td>\n",
       "      <td>3.72</td>\n",
       "      <td>3.73</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.66</td>\n",
       "      <td>222070000.0</td>\n",
       "      <td>-1.85</td>\n",
       "      <td>2025-06-23</td>\n",
       "      <td>-0.374837</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-06-24</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.82</td>\n",
       "      <td>3.90</td>\n",
       "      <td>3.77</td>\n",
       "      <td>281590000.0</td>\n",
       "      <td>1.61</td>\n",
       "      <td>2025-06-24</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-06-25</td>\n",
       "      <td>3.76</td>\n",
       "      <td>3.83</td>\n",
       "      <td>3.83</td>\n",
       "      <td>3.73</td>\n",
       "      <td>164260000.0</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>2025-06-25</td>\n",
       "      <td>-0.072154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-06-26</td>\n",
       "      <td>3.83</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.83</td>\n",
       "      <td>3.75</td>\n",
       "      <td>171430000.0</td>\n",
       "      <td>1.86</td>\n",
       "      <td>2025-06-26</td>\n",
       "      <td>0.198789</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>3.74</td>\n",
       "      <td>3.84</td>\n",
       "      <td>3.84</td>\n",
       "      <td>3.73</td>\n",
       "      <td>271930000.0</td>\n",
       "      <td>-2.35</td>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>-0.124553</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>3.70</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.67</td>\n",
       "      <td>212370000.0</td>\n",
       "      <td>-1.07</td>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>-0.018503</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-07-02</td>\n",
       "      <td>3.68</td>\n",
       "      <td>3.65</td>\n",
       "      <td>3.70</td>\n",
       "      <td>3.64</td>\n",
       "      <td>220270000.0</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>2025-07-02</td>\n",
       "      <td>-0.007767</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-07-03</td>\n",
       "      <td>3.68</td>\n",
       "      <td>3.71</td>\n",
       "      <td>3.73</td>\n",
       "      <td>3.68</td>\n",
       "      <td>119670000.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2025-07-03</td>\n",
       "      <td>0.052033</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-07-04</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.68</td>\n",
       "      <td>3.71</td>\n",
       "      <td>3.65</td>\n",
       "      <td>91140000.0</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>2025-07-04</td>\n",
       "      <td>-0.000960</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Tanggal  Terakhir  Pembukaan  Tertinggi  Terendah         Vol.  \\\n",
       "37 2025-05-05      3.86       3.90       3.92      3.86  196920000.0   \n",
       "36 2025-05-06      3.88       3.84       3.90      3.84  111330000.0   \n",
       "35 2025-05-07      3.91       3.90       3.91      3.87  119760000.0   \n",
       "34 2025-05-08      3.79       3.91       3.96      3.78  224120000.0   \n",
       "33 2025-05-09      3.84       3.81       3.84      3.76  147640000.0   \n",
       "32 2025-05-14      4.09       4.00       4.09      3.96  461640000.0   \n",
       "31 2025-05-15      4.27       4.14       4.31      4.13  537150000.0   \n",
       "30 2025-05-16      4.25       4.31       4.33      4.16  289340000.0   \n",
       "29 2025-05-19      4.23       4.23       4.26      4.20  145940000.0   \n",
       "28 2025-05-20      4.21       4.23       4.28      4.17  209580000.0   \n",
       "27 2025-05-21      4.26       4.21       4.31      4.21  256020000.0   \n",
       "26 2025-05-22      4.30       4.28       4.31      4.24  208290000.0   \n",
       "25 2025-05-23      4.35       4.37       4.37      4.33  187460000.0   \n",
       "24 2025-05-26      4.32       4.35       4.35      4.26  149420000.0   \n",
       "23 2025-05-27      4.37       4.32       4.37      4.28  180030000.0   \n",
       "22 2025-05-28      4.45       4.36       4.45      4.32  466130000.0   \n",
       "21 2025-06-02      4.20       4.36       4.39      4.20  389540000.0   \n",
       "20 2025-06-03      4.20       4.21       4.23      4.12  277900000.0   \n",
       "19 2025-06-04      4.08       4.23       4.23      4.08  279760000.0   \n",
       "18 2025-06-05      4.10       4.11       4.14      4.05  230130000.0   \n",
       "17 2025-06-10      4.15       4.10       4.16      4.10  179830000.0   \n",
       "16 2025-06-11      4.07       4.13       4.14      4.06  196560000.0   \n",
       "15 2025-06-12      4.07       4.07       4.10      4.06  113850000.0   \n",
       "14 2025-06-13      4.00       4.02       4.05      3.98  283830000.0   \n",
       "13 2025-06-16      3.99       3.98       4.01      3.96  155450000.0   \n",
       "12 2025-06-17      3.96       4.01       4.03      3.96  125770000.0   \n",
       "11 2025-06-18      3.94       3.95       3.96      3.90  140880000.0   \n",
       "10 2025-06-19      3.80       3.90       3.92      3.80  355410000.0   \n",
       "9  2025-06-20      3.79       3.74       3.84      3.74  516180000.0   \n",
       "8  2025-06-23      3.72       3.73       3.75      3.66  222070000.0   \n",
       "7  2025-06-24      3.78       3.82       3.90      3.77  281590000.0   \n",
       "6  2025-06-25      3.76       3.83       3.83      3.73  164260000.0   \n",
       "5  2025-06-26      3.83       3.78       3.83      3.75  171430000.0   \n",
       "4  2025-06-30      3.74       3.84       3.84      3.73  271930000.0   \n",
       "3  2025-07-01      3.70       3.78       3.79      3.67  212370000.0   \n",
       "2  2025-07-02      3.68       3.65       3.70      3.64  220270000.0   \n",
       "1  2025-07-03      3.68       3.71       3.73      3.68  119670000.0   \n",
       "0  2025-07-04      3.67       3.68       3.71      3.65   91140000.0   \n",
       "\n",
       "    Perubahan%        date  avg_signed_sentiment  count_positive  \\\n",
       "37       -0.52  2025-05-05              0.180110             5.0   \n",
       "36        0.52  2025-05-06             -0.010816             1.0   \n",
       "35        0.77  2025-05-07             -0.220537             0.0   \n",
       "34       -3.07  2025-05-08             -0.209798             0.0   \n",
       "33        1.32  2025-05-09              0.000000             0.0   \n",
       "32        6.51  2025-05-14             -0.085922             1.0   \n",
       "31        4.40  2025-05-15              0.075178            18.0   \n",
       "30       -0.47  2025-05-16             -0.176841             3.0   \n",
       "29       -0.47  2025-05-19              0.331064            10.0   \n",
       "28       -0.47  2025-05-20              0.048572             4.0   \n",
       "27        1.19  2025-05-21             -0.153046             0.0   \n",
       "26        0.94  2025-05-22              0.045951             3.0   \n",
       "25        1.16  2025-05-23             -0.020540             4.0   \n",
       "24       -0.69  2025-05-26             -0.128274             1.0   \n",
       "23        1.16  2025-05-27              0.302433             3.0   \n",
       "22        1.83  2025-05-28             -0.198505             2.0   \n",
       "21       -5.62  2025-06-02             -0.114793             5.0   \n",
       "20        0.00  2025-06-03             -0.014521             8.0   \n",
       "19       -2.86  2025-06-04              0.000000             0.0   \n",
       "18        0.49  2025-06-05              0.179834             3.0   \n",
       "17        1.22  2025-06-10             -0.054510             1.0   \n",
       "16       -1.93  2025-06-11              0.037650             3.0   \n",
       "15        0.00  2025-06-12              0.046693             1.0   \n",
       "14       -1.72  2025-06-13              0.163476             4.0   \n",
       "13       -0.25  2025-06-16             -0.126163             1.0   \n",
       "12       -0.75  2025-06-17              0.047399             3.0   \n",
       "11       -0.51  2025-06-18             -0.138931             4.0   \n",
       "10       -3.55  2025-06-19             -0.155275             2.0   \n",
       "9        -0.26  2025-06-20             -0.111262             2.0   \n",
       "8        -1.85  2025-06-23             -0.374837             0.0   \n",
       "7         1.61  2025-06-24              0.000000             0.0   \n",
       "6        -0.53  2025-06-25             -0.072154             0.0   \n",
       "5         1.86  2025-06-26              0.198789             1.0   \n",
       "4        -2.35  2025-06-30             -0.124553             0.0   \n",
       "3        -1.07  2025-07-01             -0.018503             4.0   \n",
       "2        -0.54  2025-07-02             -0.007767             2.0   \n",
       "1         0.00  2025-07-03              0.052033             5.0   \n",
       "0        -0.27  2025-07-04             -0.000960             4.0   \n",
       "\n",
       "    count_negative  count_neutral  total_tweets  \n",
       "37             0.0           21.0          26.0  \n",
       "36             1.0           15.0          17.0  \n",
       "35             2.0            4.0           6.0  \n",
       "34             3.0           11.0          14.0  \n",
       "33             0.0            5.0           5.0  \n",
       "32             5.0           32.0          38.0  \n",
       "31            12.0           40.0          70.0  \n",
       "30             7.0           17.0          27.0  \n",
       "29             1.0           13.0          24.0  \n",
       "28             3.0           10.0          17.0  \n",
       "27             3.0           14.0          17.0  \n",
       "26             2.0           12.0          17.0  \n",
       "25             4.0           12.0          20.0  \n",
       "24             3.0            7.0          11.0  \n",
       "23             0.0            6.0           9.0  \n",
       "22             6.0           12.0          20.0  \n",
       "21            10.0           24.0          39.0  \n",
       "20             8.0           19.0          35.0  \n",
       "19             0.0           17.0          17.0  \n",
       "18             0.0           12.0          15.0  \n",
       "17             1.0            3.0           5.0  \n",
       "16             1.0           21.0          25.0  \n",
       "15             1.0            6.0           8.0  \n",
       "14             1.0           10.0          15.0  \n",
       "13             3.0            9.0          13.0  \n",
       "12             2.0           13.0          18.0  \n",
       "11             8.0           21.0          33.0  \n",
       "10             7.0           18.0          27.0  \n",
       "9              3.0           10.0          15.0  \n",
       "8              6.0            8.0          14.0  \n",
       "7              0.0           15.0          15.0  \n",
       "6              1.0           11.0          12.0  \n",
       "5              0.0            4.0           5.0  \n",
       "4              2.0           12.0          14.0  \n",
       "3              4.0           16.0          24.0  \n",
       "2              2.0           16.0          20.0  \n",
       "1              3.0           21.0          29.0  \n",
       "0              3.0           54.0          61.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1752996559349,
     "user": {
      "displayName": "azka nuril",
      "userId": "09044520640447098125"
     },
     "user_tz": -420
    },
    "id": "uT8YF-yIR7DW"
   },
   "outputs": [],
   "source": [
    "# Fitur tambahan\n",
    "df_default['range'] = df_default['Tertinggi'] - df_default['Terendah']\n",
    "df_default['day_return'] = df_default['Terakhir'].pct_change()\n",
    "df_default['sentiment_ratio'] = df_default['count_positive'] / (df_default['count_negative'] + 1)\n",
    "df_default['tweet_intensity'] = df_default['total_tweets'] / (df_default['Vol.'] + 1)\n",
    "\n",
    "# Lag features (harga hari sebelumnya)\n",
    "df_default['lag_1'] = df_default['Terakhir'].shift(1)\n",
    "df_default['lag_2'] = df_default['Terakhir'].shift(2)\n",
    "\n",
    "# Target: apakah harga besok lebih tinggi dari hari ini?\n",
    "df_default['target'] = (df_default['Terakhir'].shift(-1) > df_default['Terakhir']).astype(int)\n",
    "\n",
    "# Tambahkan kolom deskripsi target\n",
    "df_default['keterangan_target'] = df_default['target'].map({1: 'Naik', 0: 'Turun/Stagnan'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1752996559354,
     "user": {
      "displayName": "azka nuril",
      "userId": "09044520640447098125"
     },
     "user_tz": -420
    },
    "id": "tH2YUdyE4xYd"
   },
   "outputs": [],
   "source": [
    "# Drop baris NaN\n",
    "df_default = df_default.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1752996559394,
     "user": {
      "displayName": "azka nuril",
      "userId": "09044520640447098125"
     },
     "user_tz": -420
    },
    "id": "tFHHG65f6lJN"
   },
   "outputs": [],
   "source": [
    "df_all = df_default.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1752996559407,
     "user": {
      "displayName": "azka nuril",
      "userId": "09044520640447098125"
     },
     "user_tz": -420
    },
    "id": "GOWCnaWr4z7o"
   },
   "outputs": [],
   "source": [
    "y = df_all['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Model dictionary\n",
    "models = {\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(eval_metric='logloss'),\n",
    "    \"LogReg\": LogisticRegression(max_iter=1000),\n",
    "    \"SVC\": SVC(probability=True),  # Untuk ROC AUC perlu probabilitas\n",
    "    \"MLP\": MLPClassifier(max_iter=1000, random_state=42)\n",
    "}\n",
    "\n",
    "#  Directional accuracy\n",
    "def directional_accuracy(y_true, y_pred):\n",
    "    y_true = pd.Series(y_true).reset_index(drop=True)\n",
    "    y_pred = pd.Series(y_pred).reset_index(drop=True)\n",
    "    return np.mean(np.sign(y_true.diff().fillna(0)) == np.sign(y_pred.diff().fillna(0)))\n",
    "\n",
    "#  Evaluasi model\n",
    "def evaluate_model(model_or_pipeline, X, y, model_name=\"Model\"):\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    metrics = {'accuracy': [], 'precision': [], 'recall': [], 'f1': [], 'roc_auc': [], 'directional_acc': []}\n",
    "    all_conf_matrices = []\n",
    "\n",
    "    fold = 1\n",
    "    for train_idx, test_idx in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        # Buat pipeline\n",
    "        if isinstance(model_or_pipeline, Pipeline):\n",
    "            pipeline = model_or_pipeline\n",
    "        else:\n",
    "            pipeline = Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('model', model_or_pipeline)\n",
    "            ])\n",
    "\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "\n",
    "        # Prediksi probabilitas\n",
    "        if hasattr(pipeline.named_steps['model'], \"predict_proba\"):\n",
    "            y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "        elif hasattr(pipeline.named_steps['model'], \"decision_function\"):\n",
    "            y_proba = pipeline.decision_function(X_test)\n",
    "        else:\n",
    "            y_proba = None\n",
    "\n",
    "        if len(np.unique(y_test)) > 1:\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "            rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "            f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "            cm = confusion_matrix(y_test, y_pred)\n",
    "            da = directional_accuracy(y_test, y_pred)\n",
    "\n",
    "            # ROC AUC hanya jika valid\n",
    "            if y_proba is not None and len(np.unique(y_test)) > 1:\n",
    "                try:\n",
    "                    roc_auc = roc_auc_score(y_test, y_proba)\n",
    "                except:\n",
    "                    roc_auc = 0\n",
    "            else:\n",
    "                roc_auc = 0\n",
    "\n",
    "            metrics['accuracy'].append(acc)\n",
    "            metrics['precision'].append(prec)\n",
    "            metrics['recall'].append(rec)\n",
    "            metrics['f1'].append(f1)\n",
    "            metrics['roc_auc'].append(roc_auc)\n",
    "            metrics['directional_acc'].append(da)\n",
    "            all_conf_matrices.append(cm)\n",
    "\n",
    "            print(f\"\\n Fold {fold} Confusion Matrix:\")\n",
    "            print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "            #  Visualisasi Confusion Matrix\n",
    "            # plt.figure(figsize=(5, 4))\n",
    "            # sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "            # plt.title(f\"{model_name} - Fold {fold} Confusion Matrix\")\n",
    "            # plt.xlabel(\"Predicted\")\n",
    "            # plt.ylabel(\"Actual\")\n",
    "            # plt.tight_layout()\n",
    "            # plt.show()\n",
    "\n",
    "            #  Visualisasi ROC Curve via Yellowbrick\n",
    "            # if y_proba is not None and len(np.unique(y_test)) > 1:\n",
    "            #     visualizer = ROCAUC(pipeline.named_steps['model'], classes=[\"Neg\", \"Pos\"], binary=True)\n",
    "            #     visualizer.fit(X_train, y_train)\n",
    "            #     visualizer.score(X_test, y_test)\n",
    "            #     visualizer.show()\n",
    "\n",
    "        else:\n",
    "            print(f\"\\n Fold {fold}: Only one class present in y_test, skipping metrics.\")\n",
    "\n",
    "        fold += 1\n",
    "\n",
    "    # Rata-rata dan deviasi\n",
    "    mean_metrics = {f\"{k}_mean\": np.mean(v) if v else 0 for k, v in metrics.items()}\n",
    "    std_metrics = {f\"{k}_std\": np.std(v) if v else 0 for k, v in metrics.items()}\n",
    "\n",
    "    # Logging ke MLflow\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        for k, v in mean_metrics.items():\n",
    "            mlflow.log_metric(k, v)\n",
    "        for k, v in std_metrics.items():\n",
    "            mlflow.log_metric(k, v)\n",
    "\n",
    "        input_example = X_test.head(1)\n",
    "        signature = infer_signature(X_test, y_pred)\n",
    "        mlflow.sklearn.log_model(pipeline, f\"{model_name}_model\", input_example=input_example, signature=signature)\n",
    "\n",
    "    return {**mean_metrics, **std_metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 43764,
     "status": "ok",
     "timestamp": 1752996603180,
     "user": {
      "displayName": "azka nuril",
      "userId": "09044520640447098125"
     },
     "user_tz": -420
    },
    "id": "V-9myV2h47i8",
    "outputId": "d245c8a3-071f-4877-b9b5-51f86ce94826"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tahap 1: Data Historis\n",
      "\n",
      " Evaluating RandomForest with historical data...\n",
      "\n",
      " Fold 1 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      1.00      0.50         2\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.33         6\n",
      "   macro avg       0.17      0.50      0.25         6\n",
      "weighted avg       0.11      0.33      0.17         6\n",
      "\n",
      "\n",
      " Fold 2 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.33      0.50         3\n",
      "           1       0.60      1.00      0.75         3\n",
      "\n",
      "    accuracy                           0.67         6\n",
      "   macro avg       0.80      0.67      0.62         6\n",
      "weighted avg       0.80      0.67      0.62         6\n",
      "\n",
      "\n",
      " Fold 3: Only one class present in y_test, skipping metrics.\n",
      "\n",
      " Fold 4 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.25      0.40         4\n",
      "           1       0.40      1.00      0.57         2\n",
      "\n",
      "    accuracy                           0.50         6\n",
      "   macro avg       0.70      0.62      0.49         6\n",
      "weighted avg       0.80      0.50      0.46         6\n",
      "\n",
      "\n",
      " Fold 5: Only one class present in y_test, skipping metrics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/21 22:19:01 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8aca0f31d0b48888f6d7220a9a88b1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Evaluating XGBoost with historical data...\n",
      "\n",
      " Fold 1 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      1.00      0.50         2\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.33         6\n",
      "   macro avg       0.17      0.50      0.25         6\n",
      "weighted avg       0.11      0.33      0.17         6\n",
      "\n",
      "\n",
      " Fold 2 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.25      0.33      0.29         3\n",
      "\n",
      "    accuracy                           0.17         6\n",
      "   macro avg       0.12      0.17      0.14         6\n",
      "weighted avg       0.12      0.17      0.14         6\n",
      "\n",
      "\n",
      " Fold 3: Only one class present in y_test, skipping metrics.\n",
      "\n",
      " Fold 4 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75         4\n",
      "           1       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.67         6\n",
      "   macro avg       0.62      0.62      0.62         6\n",
      "weighted avg       0.67      0.67      0.67         6\n",
      "\n",
      "\n",
      " Fold 5: Only one class present in y_test, skipping metrics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/21 22:19:07 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf9d85bada32425dbdc9bd167ca9add7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Evaluating LogReg with historical data...\n",
      "\n",
      " Fold 1 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      1.00      0.50         2\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.33         6\n",
      "   macro avg       0.17      0.50      0.25         6\n",
      "weighted avg       0.11      0.33      0.17         6\n",
      "\n",
      "\n",
      " Fold 2 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.33      0.40         3\n",
      "           1       0.50      0.67      0.57         3\n",
      "\n",
      "    accuracy                           0.50         6\n",
      "   macro avg       0.50      0.50      0.49         6\n",
      "weighted avg       0.50      0.50      0.49         6\n",
      "\n",
      "\n",
      " Fold 3: Only one class present in y_test, skipping metrics.\n",
      "\n",
      " Fold 4 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80         4\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.67         6\n",
      "   macro avg       0.33      0.50      0.40         6\n",
      "weighted avg       0.44      0.67      0.53         6\n",
      "\n",
      "\n",
      " Fold 5: Only one class present in y_test, skipping metrics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/21 22:19:11 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc68327c08ce430898343e137eb94809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Evaluating SVC with historical data...\n",
      "\n",
      " Fold 1 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      1.00      0.50         2\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.33         6\n",
      "   macro avg       0.17      0.50      0.25         6\n",
      "weighted avg       0.11      0.33      0.17         6\n",
      "\n",
      "\n",
      " Fold 2 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.50      1.00      0.67         3\n",
      "\n",
      "    accuracy                           0.50         6\n",
      "   macro avg       0.25      0.50      0.33         6\n",
      "weighted avg       0.25      0.50      0.33         6\n",
      "\n",
      "\n",
      " Fold 3: Only one class present in y_test, skipping metrics.\n",
      "\n",
      " Fold 4 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         4\n",
      "           1       0.50      1.00      0.67         2\n",
      "\n",
      "    accuracy                           0.67         6\n",
      "   macro avg       0.75      0.75      0.67         6\n",
      "weighted avg       0.83      0.67      0.67         6\n",
      "\n",
      "\n",
      " Fold 5: Only one class present in y_test, skipping metrics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/21 22:19:14 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "990881a812ab4af1a07dfa44e693a849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Evaluating MLP with historical data...\n",
      "\n",
      " Fold 1 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      1.00      0.50         2\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.33         6\n",
      "   macro avg       0.17      0.50      0.25         6\n",
      "weighted avg       0.11      0.33      0.17         6\n",
      "\n",
      "\n",
      " Fold 2 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         3\n",
      "           1       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.83         6\n",
      "   macro avg       0.88      0.83      0.83         6\n",
      "weighted avg       0.88      0.83      0.83         6\n",
      "\n",
      "\n",
      " Fold 3: Only one class present in y_test, skipping metrics.\n",
      "\n",
      " Fold 4 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.25      0.40         4\n",
      "           1       0.40      1.00      0.57         2\n",
      "\n",
      "    accuracy                           0.50         6\n",
      "   macro avg       0.70      0.62      0.49         6\n",
      "weighted avg       0.80      0.50      0.46         6\n",
      "\n",
      "\n",
      " Fold 5: Only one class present in y_test, skipping metrics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/21 22:19:18 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "823620a689e04beda2228bdd625033cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tahap 1 - Evaluasi data historis\n",
    "features_hist = ['Terakhir', 'Pembukaan', 'Tertinggi', 'Terendah', 'Vol.', 'Perubahan%', 'range', 'day_return', 'lag_1', 'lag_2']\n",
    "X_hist = df_all[features_hist]\n",
    "\n",
    "print(\" Tahap 1: Data Historis\")\n",
    "results_hist = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n Evaluating {name} with historical data...\")\n",
    "    results_hist[name] = evaluate_model(model, X_hist, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1752996603229,
     "user": {
      "displayName": "azka nuril",
      "userId": "09044520640447098125"
     },
     "user_tz": -420
    },
    "id": "HvKYl6cefi8N",
    "outputId": "7df51a02-9a19-48bf-97e5-69a30c5d3a4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Rangkuman Evaluasi Model (Tahap Historis):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_mean</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>recall_mean</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>roc_auc_mean</th>\n",
       "      <th>directional_acc_mean</th>\n",
       "      <th>accuracy_std</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>roc_auc_std</th>\n",
       "      <th>directional_acc_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.440476</td>\n",
       "      <td>0.652778</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.136083</td>\n",
       "      <td>0.249444</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.319882</td>\n",
       "      <td>0.199343</td>\n",
       "      <td>0.136083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.261905</td>\n",
       "      <td>0.310185</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.207870</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.207870</td>\n",
       "      <td>0.204817</td>\n",
       "      <td>0.187142</td>\n",
       "      <td>0.078567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.717593</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.136083</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.314270</td>\n",
       "      <td>0.269374</td>\n",
       "      <td>0.066448</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.365741</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.136083</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.314270</td>\n",
       "      <td>0.371353</td>\n",
       "      <td>0.136083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.207870</td>\n",
       "      <td>0.306413</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.356348</td>\n",
       "      <td>0.218722</td>\n",
       "      <td>0.136083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              accuracy_mean  precision_mean  recall_mean   f1_mean  \\\n",
       "RandomForest       0.500000        0.333333     0.666667  0.440476   \n",
       "XGBoost            0.388889        0.250000     0.277778  0.261905   \n",
       "LogReg             0.500000        0.166667     0.222222  0.190476   \n",
       "SVC                0.500000        0.333333     0.666667  0.444444   \n",
       "MLP                0.555556        0.383333     0.666667  0.476190   \n",
       "\n",
       "              roc_auc_mean  directional_acc_mean  accuracy_std  precision_std  \\\n",
       "RandomForest      0.652778              0.500000      0.136083       0.249444   \n",
       "XGBoost           0.310185              0.555556      0.207870       0.204124   \n",
       "LogReg            0.717593              0.500000      0.136083       0.235702   \n",
       "SVC               0.365741              0.500000      0.136083       0.235702   \n",
       "MLP               0.555556              0.500000      0.207870       0.306413   \n",
       "\n",
       "              recall_std    f1_std  roc_auc_std  directional_acc_std  \n",
       "RandomForest    0.471405  0.319882     0.199343             0.136083  \n",
       "XGBoost         0.207870  0.204817     0.187142             0.078567  \n",
       "LogReg          0.314270  0.269374     0.066448             0.000000  \n",
       "SVC             0.471405  0.314270     0.371353             0.136083  \n",
       "MLP             0.471405  0.356348     0.218722             0.136083  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Format output sebagai DataFrame\n",
    "df_historis = pd.DataFrame(results_hist).T\n",
    "print(\"\\n Rangkuman Evaluasi Model (Tahap Historis):\")\n",
    "df_historis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 26331,
     "status": "ok",
     "timestamp": 1752996629563,
     "user": {
      "displayName": "azka nuril",
      "userId": "09044520640447098125"
     },
     "user_tz": -420
    },
    "id": "G6KdM3pt_pOa",
    "outputId": "96edd03c-3782-414a-8e22-64e6a9af61c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tahap 2: Data Gabungan\n",
      "\n",
      " Evaluating RandomForest with combined data...\n",
      "\n",
      " Fold 1 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      1.00      0.50         2\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.33         6\n",
      "   macro avg       0.17      0.50      0.25         6\n",
      "weighted avg       0.11      0.33      0.17         6\n",
      "\n",
      "\n",
      " Fold 2 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         3\n",
      "           1       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.83         6\n",
      "   macro avg       0.88      0.83      0.83         6\n",
      "weighted avg       0.88      0.83      0.83         6\n",
      "\n",
      "\n",
      " Fold 3: Only one class present in y_test, skipping metrics.\n",
      "\n",
      " Fold 4 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         4\n",
      "           1       0.50      1.00      0.67         2\n",
      "\n",
      "    accuracy                           0.67         6\n",
      "   macro avg       0.75      0.75      0.67         6\n",
      "weighted avg       0.83      0.67      0.67         6\n",
      "\n",
      "\n",
      " Fold 5: Only one class present in y_test, skipping metrics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/21 22:19:22 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b12e0d6c06444f63a0b1e1c7ee31d8d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Evaluating XGBoost with combined data...\n",
      "\n",
      " Fold 1 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      1.00      0.50         2\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.33         6\n",
      "   macro avg       0.17      0.50      0.25         6\n",
      "weighted avg       0.11      0.33      0.17         6\n",
      "\n",
      "\n",
      " Fold 2 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         3\n",
      "           1       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.83         6\n",
      "   macro avg       0.88      0.83      0.83         6\n",
      "weighted avg       0.88      0.83      0.83         6\n",
      "\n",
      "\n",
      " Fold 3: Only one class present in y_test, skipping metrics.\n",
      "\n",
      " Fold 4 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86         4\n",
      "           1       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.83         6\n",
      "   macro avg       0.83      0.88      0.83         6\n",
      "weighted avg       0.89      0.83      0.84         6\n",
      "\n",
      "\n",
      " Fold 5: Only one class present in y_test, skipping metrics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/21 22:19:27 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fdeed02dda2425d99e5d5f56a1ccb78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Evaluating LogReg with combined data...\n",
      "\n",
      " Fold 1 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      1.00      0.50         2\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.33         6\n",
      "   macro avg       0.17      0.50      0.25         6\n",
      "weighted avg       0.11      0.33      0.17         6\n",
      "\n",
      "\n",
      " Fold 2 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         3\n",
      "           1       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.83         6\n",
      "   macro avg       0.88      0.83      0.83         6\n",
      "weighted avg       0.88      0.83      0.83         6\n",
      "\n",
      "\n",
      " Fold 3: Only one class present in y_test, skipping metrics.\n",
      "\n",
      " Fold 4 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75         4\n",
      "           1       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.67         6\n",
      "   macro avg       0.62      0.62      0.62         6\n",
      "weighted avg       0.67      0.67      0.67         6\n",
      "\n",
      "\n",
      " Fold 5: Only one class present in y_test, skipping metrics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/21 22:19:31 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "706cfdd06f904a6da02ca6f29aab34e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Evaluating SVC with combined data...\n",
      "\n",
      " Fold 1 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      1.00      0.50         2\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.33         6\n",
      "   macro avg       0.17      0.50      0.25         6\n",
      "weighted avg       0.11      0.33      0.17         6\n",
      "\n",
      "\n",
      " Fold 2 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.50      1.00      0.67         3\n",
      "\n",
      "    accuracy                           0.50         6\n",
      "   macro avg       0.25      0.50      0.33         6\n",
      "weighted avg       0.25      0.50      0.33         6\n",
      "\n",
      "\n",
      " Fold 3: Only one class present in y_test, skipping metrics.\n",
      "\n",
      " Fold 4 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.75      0.67         4\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.50         6\n",
      "   macro avg       0.30      0.38      0.33         6\n",
      "weighted avg       0.40      0.50      0.44         6\n",
      "\n",
      "\n",
      " Fold 5: Only one class present in y_test, skipping metrics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/21 22:19:34 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b632be7f7e4841d88dae0b214527def3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Evaluating MLP with combined data...\n",
      "\n",
      " Fold 1 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      1.00      0.50         2\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.33         6\n",
      "   macro avg       0.17      0.50      0.25         6\n",
      "weighted avg       0.11      0.33      0.17         6\n",
      "\n",
      "\n",
      " Fold 2 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         3\n",
      "           1       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.83         6\n",
      "   macro avg       0.88      0.83      0.83         6\n",
      "weighted avg       0.88      0.83      0.83         6\n",
      "\n",
      "\n",
      " Fold 3: Only one class present in y_test, skipping metrics.\n",
      "\n",
      " Fold 4 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.50      0.57         4\n",
      "           1       0.33      0.50      0.40         2\n",
      "\n",
      "    accuracy                           0.50         6\n",
      "   macro avg       0.50      0.50      0.49         6\n",
      "weighted avg       0.56      0.50      0.51         6\n",
      "\n",
      "\n",
      " Fold 5: Only one class present in y_test, skipping metrics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/21 22:19:38 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e550017b29440edb289a263b26e9bfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tahap 2 - Evaluasi data gabungan\n",
    "features_combined = [\n",
    "    'Terakhir', 'Pembukaan', 'Tertinggi', 'Terendah', 'Vol.', 'Perubahan%',\n",
    "    'avg_signed_sentiment', 'count_positive', 'count_negative', 'count_neutral', 'total_tweets',\n",
    "    'range', 'day_return', 'sentiment_ratio', 'tweet_intensity',\n",
    "    'lag_1', 'lag_2'\n",
    "]\n",
    "X_combined = df_all[features_combined]\n",
    "\n",
    "print(\" Tahap 2: Data Gabungan\")\n",
    "results_combined = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n Evaluating {name} with combined data...\")\n",
    "    results_combined[name] = evaluate_model(model, X_combined, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1752996629605,
     "user": {
      "displayName": "azka nuril",
      "userId": "09044520640447098125"
     },
     "user_tz": -420
    },
    "id": "3dRbexqggK0g",
    "outputId": "2310bf16-ee6f-4a35-c099-3b9a428ca8be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Rangkuman Evaluasi Model (Tahap Gabungan):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_mean</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>recall_mean</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>roc_auc_mean</th>\n",
       "      <th>directional_acc_mean</th>\n",
       "      <th>accuracy_std</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>roc_auc_std</th>\n",
       "      <th>directional_acc_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.507937</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.207870</td>\n",
       "      <td>0.311805</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.367487</td>\n",
       "      <td>0.117851</td>\n",
       "      <td>0.136083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.552381</td>\n",
       "      <td>0.675926</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.335640</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.391288</td>\n",
       "      <td>0.124914</td>\n",
       "      <td>0.078567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg</th>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.796296</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.207870</td>\n",
       "      <td>0.311805</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.351543</td>\n",
       "      <td>0.214367</td>\n",
       "      <td>0.078567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.078567</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.314270</td>\n",
       "      <td>0.424918</td>\n",
       "      <td>0.078567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.419048</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.207870</td>\n",
       "      <td>0.306816</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.350186</td>\n",
       "      <td>0.270031</td>\n",
       "      <td>0.136083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              accuracy_mean  precision_mean  recall_mean   f1_mean  \\\n",
       "RandomForest       0.611111        0.416667     0.666667  0.507937   \n",
       "XGBoost            0.666667        0.472222     0.666667  0.552381   \n",
       "LogReg             0.611111        0.416667     0.500000  0.452381   \n",
       "SVC                0.444444        0.166667     0.333333  0.222222   \n",
       "MLP                0.555556        0.361111     0.500000  0.419048   \n",
       "\n",
       "              roc_auc_mean  directional_acc_mean  accuracy_std  precision_std  \\\n",
       "RandomForest      0.833333              0.500000      0.207870       0.311805   \n",
       "XGBoost           0.675926              0.611111      0.235702       0.335640   \n",
       "LogReg            0.796296              0.555556      0.207870       0.311805   \n",
       "SVC               0.583333              0.555556      0.078567       0.235702   \n",
       "MLP               0.750000              0.500000      0.207870       0.306816   \n",
       "\n",
       "              recall_std    f1_std  roc_auc_std  directional_acc_std  \n",
       "RandomForest    0.471405  0.367487     0.117851             0.136083  \n",
       "XGBoost         0.471405  0.391288     0.124914             0.078567  \n",
       "LogReg          0.408248  0.351543     0.214367             0.078567  \n",
       "SVC             0.471405  0.314270     0.424918             0.078567  \n",
       "MLP             0.408248  0.350186     0.270031             0.136083  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined = pd.DataFrame(results_combined).T\n",
    "print(\"\\n Rangkuman Evaluasi Model (Tahap Gabungan):\")\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1752996629609,
     "user": {
      "displayName": "azka nuril",
      "userId": "09044520640447098125"
     },
     "user_tz": -420
    },
    "id": "LfeURF32HA9u"
   },
   "outputs": [],
   "source": [
    "def optimize_model(model, param_grid, X, y, n_splits=5):\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    grid = GridSearchCV(pipeline, param_grid=param_grid, cv=tscv, scoring='f1', n_jobs=-1)\n",
    "    grid.fit(X, y)\n",
    "    return grid.best_estimator_, grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1752996629617,
     "user": {
      "displayName": "azka nuril",
      "userId": "09044520640447098125"
     },
     "user_tz": -420
    },
    "id": "iqksghdNHjNQ",
    "outputId": "19876d4b-b789-4951-9167-f57f135a607e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Tahap 3: Optimasi Model\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Tahap 3: Optimasi Model\")\n",
    "\n",
    "optimized_models = {}\n",
    "optimized_folds = [3, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24293,
     "status": "ok",
     "timestamp": 1752996653912,
     "user": {
      "displayName": "azka nuril",
      "userId": "09044520640447098125"
     },
     "user_tz": -420
    },
    "id": "E9eGvHHaHH0Z",
    "outputId": "b688b636-f08f-428d-8bd7-58d357b671ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Optimasi Random Forest dengan 3-fold TimeSeriesSplit\n",
      " Best Params (3 fold): {'model__max_depth': None, 'model__n_estimators': 200}\n",
      "\n",
      " Optimasi Random Forest dengan 5-fold TimeSeriesSplit\n",
      " Best Params (5 fold): {'model__max_depth': None, 'model__n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "rf_grid = {\n",
    "    'model__n_estimators': [100, 200],\n",
    "    'model__max_depth': [None, 10, 20],\n",
    "}\n",
    "\n",
    "optimized_models['RandomForest'] = {}  # Buat dict nested untuk tiap fold\n",
    "\n",
    "for n_fold in optimized_folds:\n",
    "    print(f\"\\n Optimasi Random Forest dengan {n_fold}-fold TimeSeriesSplit\")\n",
    "    best_rf, best_rf_params = optimize_model(\n",
    "        RandomForestClassifier(random_state=42),\n",
    "        rf_grid,\n",
    "        X_combined, y,\n",
    "        n_splits=n_fold  # pastikan fungsi optimize_model menerima ini\n",
    "    )\n",
    "    print(f\" Best Params ({n_fold} fold):\", best_rf_params)\n",
    "\n",
    "    # Simpan berdasarkan jumlah fold\n",
    "    optimized_models['RandomForest'][f'{n_fold}_fold'] = {\n",
    "        'model': best_rf,\n",
    "        'params': best_rf_params\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5305,
     "status": "ok",
     "timestamp": 1752996659215,
     "user": {
      "displayName": "azka nuril",
      "userId": "09044520640447098125"
     },
     "user_tz": -420
    },
    "id": "uAdVI7MPIa2r",
    "outputId": "b96f99e6-9565-45d8-da27-4490f41c9729"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Optimasi XGBoost dengan 3-fold TimeSeriesSplit\n",
      " Best Params (3 fold): {'model__learning_rate': 0.05, 'model__max_depth': 3, 'model__n_estimators': 100}\n",
      "\n",
      " Optimasi XGBoost dengan 5-fold TimeSeriesSplit\n",
      " Best Params (5 fold): {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "\n",
    "xgb_grid = {\n",
    "    'model__n_estimators': [100, 200],\n",
    "    'model__max_depth': [3, 6],\n",
    "    'model__learning_rate': [0.05, 0.1]\n",
    "}\n",
    "\n",
    "optimized_models['XGBoost'] = {}  # Buat dict nested untuk tiap fold\n",
    "\n",
    "for n_fold in optimized_folds:\n",
    "    print(f\"\\n Optimasi XGBoost dengan {n_fold}-fold TimeSeriesSplit\")\n",
    "    best_xgb, best_xgb_params = optimize_model(\n",
    "        XGBClassifier(eval_metric='logloss'),\n",
    "        xgb_grid,\n",
    "        X_combined, y,\n",
    "        n_splits=n_fold  # pastikan fungsi optimize_model menerima ini\n",
    "    )\n",
    "    print(f\" Best Params ({n_fold} fold):\", best_xgb_params)\n",
    "\n",
    "    # Simpan berdasarkan jumlah fold\n",
    "    optimized_models['XGBoost'][f'{n_fold}_fold'] = {\n",
    "        'model': best_xgb,\n",
    "        'params': best_xgb_params\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 850,
     "status": "ok",
     "timestamp": 1752996660082,
     "user": {
      "displayName": "azka nuril",
      "userId": "09044520640447098125"
     },
     "user_tz": -420
    },
    "id": "e7Wv407fJDGe",
    "outputId": "10f4e43e-5400-4042-b5bc-2f102d6685df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Optimasi LogReg dengan 3-fold TimeSeriesSplit\n",
      " Best Params (3 fold): {'model__C': 0.1, 'model__penalty': 'l2', 'model__solver': 'lbfgs'}\n",
      "\n",
      " Optimasi LogReg dengan 5-fold TimeSeriesSplit\n",
      " Best Params (5 fold): {'model__C': 1, 'model__penalty': 'l2', 'model__solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "# LogReg\n",
    "\n",
    "logreg_grid = {\n",
    "    'model__C': [0.01, 0.1, 1, 10],\n",
    "    'model__penalty': ['l2'],\n",
    "    'model__solver': ['lbfgs']\n",
    "}\n",
    "\n",
    "optimized_models['LogReg'] = {}  # Buat dict nested untuk tiap fold\n",
    "\n",
    "for n_fold in optimized_folds:\n",
    "    print(f\"\\n Optimasi LogReg dengan {n_fold}-fold TimeSeriesSplit\")\n",
    "    best_logreg, best_logreg_params = optimize_model(\n",
    "        LogisticRegression(max_iter=1000),\n",
    "        logreg_grid,\n",
    "        X_combined, y,\n",
    "        n_splits=n_fold  # pastikan fungsi optimize_model menerima ini\n",
    "    )\n",
    "    print(f\" Best Params ({n_fold} fold):\", best_logreg_params)\n",
    "\n",
    "    # Simpan berdasarkan jumlah fold\n",
    "    optimized_models['LogReg'][f'{n_fold}_fold'] = {\n",
    "        'model': best_logreg,\n",
    "        'params': best_logreg_params\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1768,
     "status": "ok",
     "timestamp": 1752996661851,
     "user": {
      "displayName": "azka nuril",
      "userId": "09044520640447098125"
     },
     "user_tz": -420
    },
    "id": "YPI0k2J4JXYJ",
    "outputId": "5b0f06a0-f9f3-48bd-e4ad-9aba701473fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Optimasi SVC dengan 3-fold TimeSeriesSplit\n",
      " Best Params (3 fold): {'model__C': 10, 'model__gamma': 'scale', 'model__kernel': 'rbf'}\n",
      "\n",
      " Optimasi SVC dengan 5-fold TimeSeriesSplit\n",
      " Best Params (5 fold): {'model__C': 10, 'model__gamma': 'scale', 'model__kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# SVC\n",
    "\n",
    "svc_grid = {\n",
    "    'model__C': [0.1, 1, 10],\n",
    "    'model__kernel': ['linear', 'rbf'],\n",
    "    'model__gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "optimized_models['SVC'] = {}  # Buat dict nested untuk tiap fold\n",
    "\n",
    "for n_fold in optimized_folds:\n",
    "    print(f\"\\n Optimasi SVC dengan {n_fold}-fold TimeSeriesSplit\")\n",
    "    best_svc, best_svc_params = optimize_model(\n",
    "        SVC(),\n",
    "        svc_grid,\n",
    "        X_combined, y,\n",
    "        n_splits=n_fold  # pastikan fungsi optimize_model menerima ini\n",
    "    )\n",
    "    print(f\" Best Params ({n_fold} fold):\", best_svc_params)\n",
    "\n",
    "    # Simpan berdasarkan jumlah fold\n",
    "    optimized_models['SVC'][f'{n_fold}_fold'] = {\n",
    "        'model': best_svc,\n",
    "        'params': best_svc_params\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20993,
     "status": "ok",
     "timestamp": 1752996682849,
     "user": {
      "displayName": "azka nuril",
      "userId": "09044520640447098125"
     },
     "user_tz": -420
    },
    "id": "2wJEZXbvT26B",
    "outputId": "a7af3866-d00d-4fc1-db6a-2c5ebc4fbd5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Optimasi mlp dengan 3-fold TimeSeriesSplit\n",
      " Best Params (3 fold): {'model__activation': 'tanh', 'model__alpha': 0.0001, 'model__hidden_layer_sizes': (100,)}\n",
      "\n",
      " Optimasi mlp dengan 5-fold TimeSeriesSplit\n",
      " Best Params (5 fold): {'model__activation': 'relu', 'model__alpha': 0.0001, 'model__hidden_layer_sizes': (50, 50)}\n"
     ]
    }
   ],
   "source": [
    "# MLP\n",
    "\n",
    "mlp_grid = {\n",
    "    'model__hidden_layer_sizes': [(100,), (50, 50)],\n",
    "    'model__activation': ['relu', 'tanh'],\n",
    "    'model__alpha': [0.0001, 0.001]\n",
    "}\n",
    "\n",
    "optimized_models['MLP'] = {}  # Buat dict nested untuk tiap fold\n",
    "\n",
    "for n_fold in optimized_folds:\n",
    "    print(f\"\\n Optimasi mlp dengan {n_fold}-fold TimeSeriesSplit\")\n",
    "    best_mlp, best_mlp_params = optimize_model(\n",
    "        MLPClassifier(max_iter=1000, random_state=42),\n",
    "        mlp_grid,\n",
    "        X_combined, y,\n",
    "        n_splits=n_fold  # pastikan fungsi optimize_model menerima ini\n",
    "    )\n",
    "    print(f\" Best Params ({n_fold} fold):\", best_mlp_params)\n",
    "\n",
    "    # Simpan berdasarkan jumlah fold\n",
    "    optimized_models['MLP'][f'{n_fold}_fold'] = {\n",
    "        'model': best_mlp,\n",
    "        'params': best_mlp_params\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1y8JgOpoxAPJsbNdBYBdZXhJ_uRfSPQ3d"
    },
    "executionInfo": {
     "elapsed": 80168,
     "status": "ok",
     "timestamp": 1752996763020,
     "user": {
      "displayName": "azka nuril",
      "userId": "09044520640447098125"
     },
     "user_tz": -420
    },
    "id": "mwC9ZYI4Bnyh",
    "outputId": "492f62f7-029b-416b-b97d-cd70dd2276a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Evaluasi Ulang Setelah Optimasi\n",
      "\n",
      " Fold 1 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      1.00      0.50         2\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.33         6\n",
      "   macro avg       0.17      0.50      0.25         6\n",
      "weighted avg       0.11      0.33      0.17         6\n",
      "\n",
      "\n",
      " Fold 2 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         3\n",
      "           1       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.83         6\n",
      "   macro avg       0.88      0.83      0.83         6\n",
      "weighted avg       0.88      0.83      0.83         6\n",
      "\n",
      "\n",
      " Fold 3: Only one class present in y_test, skipping metrics.\n",
      "\n",
      " Fold 4 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         4\n",
      "           1       0.50      1.00      0.67         2\n",
      "\n",
      "    accuracy                           0.67         6\n",
      "   macro avg       0.75      0.75      0.67         6\n",
      "weighted avg       0.83      0.67      0.67         6\n",
      "\n",
      "\n",
      " Fold 5: Only one class present in y_test, skipping metrics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/21 22:19:56 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "335989c304a8452c91edabd5cb35b30d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fold 1 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      1.00      0.50         2\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.33         6\n",
      "   macro avg       0.17      0.50      0.25         6\n",
      "weighted avg       0.11      0.33      0.17         6\n",
      "\n",
      "\n",
      " Fold 2 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         3\n",
      "           1       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.83         6\n",
      "   macro avg       0.88      0.83      0.83         6\n",
      "weighted avg       0.88      0.83      0.83         6\n",
      "\n",
      "\n",
      " Fold 3: Only one class present in y_test, skipping metrics.\n",
      "\n",
      " Fold 4 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         4\n",
      "           1       0.50      1.00      0.67         2\n",
      "\n",
      "    accuracy                           0.67         6\n",
      "   macro avg       0.75      0.75      0.67         6\n",
      "weighted avg       0.83      0.67      0.67         6\n",
      "\n",
      "\n",
      " Fold 5: Only one class present in y_test, skipping metrics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/21 22:20:00 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a251643e8fa4d0a8d8aaed6b995a647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fold 1 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      1.00      0.50         2\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.33         6\n",
      "   macro avg       0.17      0.50      0.25         6\n",
      "weighted avg       0.11      0.33      0.17         6\n",
      "\n",
      "\n",
      " Fold 2 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         3\n",
      "           1       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.83         6\n",
      "   macro avg       0.88      0.83      0.83         6\n",
      "weighted avg       0.88      0.83      0.83         6\n",
      "\n",
      "\n",
      " Fold 3: Only one class present in y_test, skipping metrics.\n",
      "\n",
      " Fold 4 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.25      0.40         4\n",
      "           1       0.40      1.00      0.57         2\n",
      "\n",
      "    accuracy                           0.50         6\n",
      "   macro avg       0.70      0.62      0.49         6\n",
      "weighted avg       0.80      0.50      0.46         6\n",
      "\n",
      "\n",
      " Fold 5: Only one class present in y_test, skipping metrics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/21 22:20:05 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45c0ca5f363d44098b0ceb6c80003e24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fold 1 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      1.00      0.50         2\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.33         6\n",
      "   macro avg       0.17      0.50      0.25         6\n",
      "weighted avg       0.11      0.33      0.17         6\n",
      "\n",
      "\n",
      " Fold 2 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         3\n",
      "           1       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.83         6\n",
      "   macro avg       0.88      0.83      0.83         6\n",
      "weighted avg       0.88      0.83      0.83         6\n",
      "\n",
      "\n",
      " Fold 3: Only one class present in y_test, skipping metrics.\n",
      "\n",
      " Fold 4 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86         4\n",
      "           1       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.83         6\n",
      "   macro avg       0.83      0.88      0.83         6\n",
      "weighted avg       0.89      0.83      0.84         6\n",
      "\n",
      "\n",
      " Fold 5: Only one class present in y_test, skipping metrics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/21 22:20:09 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86540a44bb7e4f00aaf70b351ff7944d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fold 1 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      1.00      0.50         2\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.33         6\n",
      "   macro avg       0.17      0.50      0.25         6\n",
      "weighted avg       0.11      0.33      0.17         6\n",
      "\n",
      "\n",
      " Fold 2 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         3\n",
      "           1       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.83         6\n",
      "   macro avg       0.88      0.83      0.83         6\n",
      "weighted avg       0.88      0.83      0.83         6\n",
      "\n",
      "\n",
      " Fold 3: Only one class present in y_test, skipping metrics.\n",
      "\n",
      " Fold 4 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.75      0.67         4\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.50         6\n",
      "   macro avg       0.30      0.38      0.33         6\n",
      "weighted avg       0.40      0.50      0.44         6\n",
      "\n",
      "\n",
      " Fold 5: Only one class present in y_test, skipping metrics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/21 22:20:12 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0506ced20ff643af813789d50cd93edc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fold 1 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      1.00      0.50         2\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.33         6\n",
      "   macro avg       0.17      0.50      0.25         6\n",
      "weighted avg       0.11      0.33      0.17         6\n",
      "\n",
      "\n",
      " Fold 2 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         3\n",
      "           1       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.83         6\n",
      "   macro avg       0.88      0.83      0.83         6\n",
      "weighted avg       0.88      0.83      0.83         6\n",
      "\n",
      "\n",
      " Fold 3: Only one class present in y_test, skipping metrics.\n",
      "\n",
      " Fold 4 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75         4\n",
      "           1       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.67         6\n",
      "   macro avg       0.62      0.62      0.62         6\n",
      "weighted avg       0.67      0.67      0.67         6\n",
      "\n",
      "\n",
      " Fold 5: Only one class present in y_test, skipping metrics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/21 22:20:16 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "125cd7e1165b4df0bf783c14064a1244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fold 1 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      1.00      0.50         2\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.33         6\n",
      "   macro avg       0.17      0.50      0.25         6\n",
      "weighted avg       0.11      0.33      0.17         6\n",
      "\n",
      "\n",
      " Fold 2 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00         6\n",
      "   macro avg       1.00      1.00      1.00         6\n",
      "weighted avg       1.00      1.00      1.00         6\n",
      "\n",
      "\n",
      " Fold 3: Only one class present in y_test, skipping metrics.\n",
      "\n",
      " Fold 4 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         4\n",
      "           1       0.50      1.00      0.67         2\n",
      "\n",
      "    accuracy                           0.67         6\n",
      "   macro avg       0.75      0.75      0.67         6\n",
      "weighted avg       0.83      0.67      0.67         6\n",
      "\n",
      "\n",
      " Fold 5: Only one class present in y_test, skipping metrics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/21 22:20:19 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16c33fe60d604e1bb07546b910f1130b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fold 1 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      1.00      0.50         2\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.33         6\n",
      "   macro avg       0.17      0.50      0.25         6\n",
      "weighted avg       0.11      0.33      0.17         6\n",
      "\n",
      "\n",
      " Fold 2 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00         6\n",
      "   macro avg       1.00      1.00      1.00         6\n",
      "weighted avg       1.00      1.00      1.00         6\n",
      "\n",
      "\n",
      " Fold 3: Only one class present in y_test, skipping metrics.\n",
      "\n",
      " Fold 4 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         4\n",
      "           1       0.50      1.00      0.67         2\n",
      "\n",
      "    accuracy                           0.67         6\n",
      "   macro avg       0.75      0.75      0.67         6\n",
      "weighted avg       0.83      0.67      0.67         6\n",
      "\n",
      "\n",
      " Fold 5: Only one class present in y_test, skipping metrics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/21 22:20:23 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bc84398f788487faa54bd5d0a4ed8f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fold 1 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      1.00      0.50         2\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.33         6\n",
      "   macro avg       0.17      0.50      0.25         6\n",
      "weighted avg       0.11      0.33      0.17         6\n",
      "\n",
      "\n",
      " Fold 2 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         3\n",
      "           1       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.83         6\n",
      "   macro avg       0.88      0.83      0.83         6\n",
      "weighted avg       0.88      0.83      0.83         6\n",
      "\n",
      "\n",
      " Fold 3: Only one class present in y_test, skipping metrics.\n",
      "\n",
      " Fold 4 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75         4\n",
      "           1       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.67         6\n",
      "   macro avg       0.62      0.62      0.62         6\n",
      "weighted avg       0.67      0.67      0.67         6\n",
      "\n",
      "\n",
      " Fold 5: Only one class present in y_test, skipping metrics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/21 22:20:26 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab7884ee5c844987aa38e4152d35c419",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fold 1 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      1.00      0.50         2\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.33         6\n",
      "   macro avg       0.17      0.50      0.25         6\n",
      "weighted avg       0.11      0.33      0.17         6\n",
      "\n",
      "\n",
      " Fold 2 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00         6\n",
      "   macro avg       1.00      1.00      1.00         6\n",
      "weighted avg       1.00      1.00      1.00         6\n",
      "\n",
      "\n",
      " Fold 3: Only one class present in y_test, skipping metrics.\n",
      "\n",
      " Fold 4 Confusion Matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.50      0.57         4\n",
      "           1       0.33      0.50      0.40         2\n",
      "\n",
      "    accuracy                           0.50         6\n",
      "   macro avg       0.50      0.50      0.49         6\n",
      "weighted avg       0.56      0.50      0.51         6\n",
      "\n",
      "\n",
      " Fold 5: Only one class present in y_test, skipping metrics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/21 22:20:30 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c987a9f2b944d16b0b0574c5f2c44e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n Evaluasi Ulang Setelah Optimasi\")\n",
    "results_optimized = {}\n",
    "for name, folds_dict in optimized_models.items():\n",
    "    for fold_name, content in folds_dict.items():\n",
    "        model = content['model']\n",
    "        key = f\"{name}_{fold_name}\"\n",
    "        results_optimized[key] = evaluate_model(model, X_combined, y, model_name=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 554
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1752996763082,
     "user": {
      "displayName": "azka nuril",
      "userId": "09044520640447098125"
     },
     "user_tz": -420
    },
    "id": "uMxAMHP-B8tr",
    "outputId": "7856540b-7cdc-428e-c852-438fb071c53b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Rangkuman Evaluasi Model (Tahap Optimasi):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_mean</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>recall_mean</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>roc_auc_mean</th>\n",
       "      <th>directional_acc_mean</th>\n",
       "      <th>accuracy_std</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>roc_auc_std</th>\n",
       "      <th>directional_acc_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForest_3_fold</th>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.507937</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.207870</td>\n",
       "      <td>0.311805</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.367487</td>\n",
       "      <td>0.106230</td>\n",
       "      <td>0.136083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest_5_fold</th>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.507937</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.207870</td>\n",
       "      <td>0.311805</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.367487</td>\n",
       "      <td>0.117851</td>\n",
       "      <td>0.136083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost_3_fold</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.207870</td>\n",
       "      <td>0.306413</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.356348</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.136083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost_5_fold</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.552381</td>\n",
       "      <td>0.675926</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.335640</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.391288</td>\n",
       "      <td>0.124914</td>\n",
       "      <td>0.078567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg_3_fold</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.800926</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.207870</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.404061</td>\n",
       "      <td>0.153966</td>\n",
       "      <td>0.078567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg_5_fold</th>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.796296</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.207870</td>\n",
       "      <td>0.311805</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.351543</td>\n",
       "      <td>0.214367</td>\n",
       "      <td>0.078567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC_3_fold</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.272166</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.415740</td>\n",
       "      <td>0.424918</td>\n",
       "      <td>0.283279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC_5_fold</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.272166</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.415740</td>\n",
       "      <td>0.424918</td>\n",
       "      <td>0.283279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP_3_fold</th>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.207870</td>\n",
       "      <td>0.311805</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.351543</td>\n",
       "      <td>0.155902</td>\n",
       "      <td>0.078567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP_5_fold</th>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.283279</td>\n",
       "      <td>0.415740</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.410961</td>\n",
       "      <td>0.294628</td>\n",
       "      <td>0.283279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     accuracy_mean  precision_mean  recall_mean   f1_mean  \\\n",
       "RandomForest_3_fold       0.611111        0.416667     0.666667  0.507937   \n",
       "RandomForest_5_fold       0.611111        0.416667     0.666667  0.507937   \n",
       "XGBoost_3_fold            0.555556        0.383333     0.666667  0.476190   \n",
       "XGBoost_5_fold            0.666667        0.472222     0.666667  0.552381   \n",
       "LogReg_3_fold             0.555556        0.250000     0.333333  0.285714   \n",
       "LogReg_5_fold             0.611111        0.416667     0.500000  0.452381   \n",
       "SVC_3_fold                0.666667        0.500000     0.666667  0.555556   \n",
       "SVC_5_fold                0.666667        0.500000     0.666667  0.555556   \n",
       "MLP_3_fold                0.611111        0.416667     0.500000  0.452381   \n",
       "MLP_5_fold                0.611111        0.444444     0.500000  0.466667   \n",
       "\n",
       "                     roc_auc_mean  directional_acc_mean  accuracy_std  \\\n",
       "RandomForest_3_fold      0.895833              0.500000      0.207870   \n",
       "RandomForest_5_fold      0.833333              0.500000      0.207870   \n",
       "XGBoost_3_fold           0.833333              0.500000      0.207870   \n",
       "XGBoost_5_fold           0.675926              0.611111      0.235702   \n",
       "LogReg_3_fold            0.800926              0.555556      0.207870   \n",
       "LogReg_5_fold            0.796296              0.555556      0.207870   \n",
       "SVC_3_fold               0.583333              0.611111      0.272166   \n",
       "SVC_5_fold               0.583333              0.611111      0.272166   \n",
       "MLP_3_fold               0.791667              0.555556      0.207870   \n",
       "MLP_5_fold               0.791667              0.611111      0.283279   \n",
       "\n",
       "                     precision_std  recall_std    f1_std  roc_auc_std  \\\n",
       "RandomForest_3_fold       0.311805    0.471405  0.367487     0.106230   \n",
       "RandomForest_5_fold       0.311805    0.471405  0.367487     0.117851   \n",
       "XGBoost_3_fold            0.306413    0.471405  0.356348     0.235702   \n",
       "XGBoost_5_fold            0.335640    0.471405  0.391288     0.124914   \n",
       "LogReg_3_fold             0.353553    0.471405  0.404061     0.153966   \n",
       "LogReg_5_fold             0.311805    0.408248  0.351543     0.214367   \n",
       "SVC_3_fold                0.408248    0.471405  0.415740     0.424918   \n",
       "SVC_5_fold                0.408248    0.471405  0.415740     0.424918   \n",
       "MLP_3_fold                0.311805    0.408248  0.351543     0.155902   \n",
       "MLP_5_fold                0.415740    0.408248  0.410961     0.294628   \n",
       "\n",
       "                     directional_acc_std  \n",
       "RandomForest_3_fold             0.136083  \n",
       "RandomForest_5_fold             0.136083  \n",
       "XGBoost_3_fold                  0.136083  \n",
       "XGBoost_5_fold                  0.078567  \n",
       "LogReg_3_fold                   0.078567  \n",
       "LogReg_5_fold                   0.078567  \n",
       "SVC_3_fold                      0.283279  \n",
       "SVC_5_fold                      0.283279  \n",
       "MLP_3_fold                      0.078567  \n",
       "MLP_5_fold                      0.283279  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_optimized = pd.DataFrame(results_optimized).T\n",
    "print(\"\\n Rangkuman Evaluasi Model (Tahap Optimasi):\")\n",
    "df_optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>accuracy_mean</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>recall_mean</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>roc_auc_mean</th>\n",
       "      <th>directional_acc_mean</th>\n",
       "      <th>accuracy_std</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>roc_auc_std</th>\n",
       "      <th>directional_acc_std</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogReg_5_fold</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.796296</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.207870</td>\n",
       "      <td>0.311805</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.351543</td>\n",
       "      <td>0.214367</td>\n",
       "      <td>0.078567</td>\n",
       "      <td>LogReg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MLP_5_fold</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.283279</td>\n",
       "      <td>0.415740</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.410961</td>\n",
       "      <td>0.294628</td>\n",
       "      <td>0.283279</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest_3_fold</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.507937</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.207870</td>\n",
       "      <td>0.311805</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.367487</td>\n",
       "      <td>0.106230</td>\n",
       "      <td>0.136083</td>\n",
       "      <td>RandomForest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVC_3_fold</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.272166</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.415740</td>\n",
       "      <td>0.424918</td>\n",
       "      <td>0.283279</td>\n",
       "      <td>SVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost_5_fold</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.552381</td>\n",
       "      <td>0.675926</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.335640</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.391288</td>\n",
       "      <td>0.124914</td>\n",
       "      <td>0.078567</td>\n",
       "      <td>XGBoost</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model_name  accuracy_mean  precision_mean  recall_mean   f1_mean  \\\n",
       "5        LogReg_5_fold       0.611111        0.416667     0.500000  0.452381   \n",
       "9           MLP_5_fold       0.611111        0.444444     0.500000  0.466667   \n",
       "0  RandomForest_3_fold       0.611111        0.416667     0.666667  0.507937   \n",
       "6           SVC_3_fold       0.666667        0.500000     0.666667  0.555556   \n",
       "3       XGBoost_5_fold       0.666667        0.472222     0.666667  0.552381   \n",
       "\n",
       "   roc_auc_mean  directional_acc_mean  accuracy_std  precision_std  \\\n",
       "5      0.796296              0.555556      0.207870       0.311805   \n",
       "9      0.791667              0.611111      0.283279       0.415740   \n",
       "0      0.895833              0.500000      0.207870       0.311805   \n",
       "6      0.583333              0.611111      0.272166       0.408248   \n",
       "3      0.675926              0.611111      0.235702       0.335640   \n",
       "\n",
       "   recall_std    f1_std  roc_auc_std  directional_acc_std         model  \n",
       "5    0.408248  0.351543     0.214367             0.078567        LogReg  \n",
       "9    0.408248  0.410961     0.294628             0.283279           MLP  \n",
       "0    0.471405  0.367487     0.106230             0.136083  RandomForest  \n",
       "6    0.471405  0.415740     0.424918             0.283279           SVC  \n",
       "3    0.471405  0.391288     0.124914             0.078567       XGBoost  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_optimized_pro = df_optimized.copy()\n",
    "\n",
    "df_optimized_pro = df_optimized_pro.reset_index()\n",
    "df_optimized_pro.rename(columns={'index': 'model_name'}, inplace=True)\n",
    "\n",
    "# Ekstrak nama algoritma: RandomForest, XGBoost, LogReg, SVC, MLP\n",
    "df_optimized_pro['model'] = df_optimized_pro['model_name'].str.extract(r'^([A-Za-z]+)')\n",
    "\n",
    "# Pastikan kolom f1_mean bertipe float (hindari NaN/string)\n",
    "df_optimized_pro['f1_mean'] = pd.to_numeric(df_optimized_pro['f1_mean'], errors='coerce')\n",
    "\n",
    "# Ambil model terbaik (berdasarkan f1 tertinggi) untuk setiap algoritma\n",
    "best_models = df_optimized_pro.loc[df_optimized_pro.groupby('model')['f1_mean'].idxmax()]\n",
    "best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy_mean</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>recall_mean</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>roc_auc_mean</th>\n",
       "      <th>directional_acc_mean</th>\n",
       "      <th>accuracy_std</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>roc_auc_std</th>\n",
       "      <th>directional_acc_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.440476</td>\n",
       "      <td>0.652778</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.136083</td>\n",
       "      <td>0.249444</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.319882</td>\n",
       "      <td>0.199343</td>\n",
       "      <td>0.136083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.261905</td>\n",
       "      <td>0.310185</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.207870</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.207870</td>\n",
       "      <td>0.204817</td>\n",
       "      <td>0.187142</td>\n",
       "      <td>0.078567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.717593</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.136083</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.314270</td>\n",
       "      <td>0.269374</td>\n",
       "      <td>0.066448</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.365741</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.136083</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.314270</td>\n",
       "      <td>0.371353</td>\n",
       "      <td>0.136083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.207870</td>\n",
       "      <td>0.306413</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.356348</td>\n",
       "      <td>0.218722</td>\n",
       "      <td>0.136083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model  accuracy_mean  precision_mean  recall_mean   f1_mean  \\\n",
       "0  RandomForest       0.500000        0.333333     0.666667  0.440476   \n",
       "1       XGBoost       0.388889        0.250000     0.277778  0.261905   \n",
       "2        LogReg       0.500000        0.166667     0.222222  0.190476   \n",
       "3           SVC       0.500000        0.333333     0.666667  0.444444   \n",
       "4           MLP       0.555556        0.383333     0.666667  0.476190   \n",
       "\n",
       "   roc_auc_mean  directional_acc_mean  accuracy_std  precision_std  \\\n",
       "0      0.652778              0.500000      0.136083       0.249444   \n",
       "1      0.310185              0.555556      0.207870       0.204124   \n",
       "2      0.717593              0.500000      0.136083       0.235702   \n",
       "3      0.365741              0.500000      0.136083       0.235702   \n",
       "4      0.555556              0.500000      0.207870       0.306413   \n",
       "\n",
       "   recall_std    f1_std  roc_auc_std  directional_acc_std  \n",
       "0    0.471405  0.319882     0.199343             0.136083  \n",
       "1    0.207870  0.204817     0.187142             0.078567  \n",
       "2    0.314270  0.269374     0.066448             0.000000  \n",
       "3    0.471405  0.314270     0.371353             0.136083  \n",
       "4    0.471405  0.356348     0.218722             0.136083  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_historis_pro = df_historis.copy()\n",
    "\n",
    "df_historis_pro = df_historis_pro.reset_index()\n",
    "df_historis_pro.rename(columns={'index': 'model'}, inplace=True)\n",
    "\n",
    "# Ekstrak nama algoritma: RandomForest, XGBoost, LogReg, SVC, MLP\n",
    "df_historis_pro['model'] = df_historis_pro['model'].str.extract(r'^([A-Za-z]+)')\n",
    "df_historis_pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy_mean</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>recall_mean</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>roc_auc_mean</th>\n",
       "      <th>directional_acc_mean</th>\n",
       "      <th>accuracy_std</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>roc_auc_std</th>\n",
       "      <th>directional_acc_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.507937</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.207870</td>\n",
       "      <td>0.311805</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.367487</td>\n",
       "      <td>0.117851</td>\n",
       "      <td>0.136083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.552381</td>\n",
       "      <td>0.675926</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.335640</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.391288</td>\n",
       "      <td>0.124914</td>\n",
       "      <td>0.078567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.796296</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.207870</td>\n",
       "      <td>0.311805</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.351543</td>\n",
       "      <td>0.214367</td>\n",
       "      <td>0.078567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.078567</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.314270</td>\n",
       "      <td>0.424918</td>\n",
       "      <td>0.078567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.419048</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.207870</td>\n",
       "      <td>0.306816</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.350186</td>\n",
       "      <td>0.270031</td>\n",
       "      <td>0.136083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model  accuracy_mean  precision_mean  recall_mean   f1_mean  \\\n",
       "0  RandomForest       0.611111        0.416667     0.666667  0.507937   \n",
       "1       XGBoost       0.666667        0.472222     0.666667  0.552381   \n",
       "2        LogReg       0.611111        0.416667     0.500000  0.452381   \n",
       "3           SVC       0.444444        0.166667     0.333333  0.222222   \n",
       "4           MLP       0.555556        0.361111     0.500000  0.419048   \n",
       "\n",
       "   roc_auc_mean  directional_acc_mean  accuracy_std  precision_std  \\\n",
       "0      0.833333              0.500000      0.207870       0.311805   \n",
       "1      0.675926              0.611111      0.235702       0.335640   \n",
       "2      0.796296              0.555556      0.207870       0.311805   \n",
       "3      0.583333              0.555556      0.078567       0.235702   \n",
       "4      0.750000              0.500000      0.207870       0.306816   \n",
       "\n",
       "   recall_std    f1_std  roc_auc_std  directional_acc_std  \n",
       "0    0.471405  0.367487     0.117851             0.136083  \n",
       "1    0.471405  0.391288     0.124914             0.078567  \n",
       "2    0.408248  0.351543     0.214367             0.078567  \n",
       "3    0.471405  0.314270     0.424918             0.078567  \n",
       "4    0.408248  0.350186     0.270031             0.136083  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined_pro = df_combined.copy()\n",
    "\n",
    "df_combined_pro = df_combined_pro.reset_index()\n",
    "df_combined_pro.rename(columns={'index': 'model'}, inplace=True)\n",
    "\n",
    "# Ekstrak nama algoritma: RandomForest, XGBoost, LogReg, SVC, MLP\n",
    "df_combined_pro['model'] = df_combined_pro['model'].str.extract(r'^([A-Za-z]+)')\n",
    "df_combined_pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tambahkan kolom untuk penanda dataframe (eksperimen)\n",
    "df_historis_pro['source'] = 'Model Historis'\n",
    "df_combined_pro['source'] = 'Model Gabungan'\n",
    "best_models['source'] = 'Model Optimasi'\n",
    "\n",
    "# Gabungkan semua dataframe\n",
    "df_all = pd.concat([df_historis_pro, df_combined_pro, best_models], ignore_index=True)\n",
    "\n",
    "order = ['Model Historis', 'Model Gabungan', 'Model Optimasi']\n",
    "df_all['source'] = pd.Categorical(df_all['source'], categories=order, ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy_mean</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>recall_mean</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>roc_auc_mean</th>\n",
       "      <th>directional_acc_mean</th>\n",
       "      <th>accuracy_std</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>roc_auc_std</th>\n",
       "      <th>directional_acc_std</th>\n",
       "      <th>source</th>\n",
       "      <th>model_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.440476</td>\n",
       "      <td>0.652778</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.136083</td>\n",
       "      <td>0.249444</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.319882</td>\n",
       "      <td>0.199343</td>\n",
       "      <td>0.136083</td>\n",
       "      <td>Model Historis</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.261905</td>\n",
       "      <td>0.310185</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.207870</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.207870</td>\n",
       "      <td>0.204817</td>\n",
       "      <td>0.187142</td>\n",
       "      <td>0.078567</td>\n",
       "      <td>Model Historis</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.717593</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.136083</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.314270</td>\n",
       "      <td>0.269374</td>\n",
       "      <td>0.066448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Model Historis</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.365741</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.136083</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.314270</td>\n",
       "      <td>0.371353</td>\n",
       "      <td>0.136083</td>\n",
       "      <td>Model Historis</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.207870</td>\n",
       "      <td>0.306413</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.356348</td>\n",
       "      <td>0.218722</td>\n",
       "      <td>0.136083</td>\n",
       "      <td>Model Historis</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.507937</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.207870</td>\n",
       "      <td>0.311805</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.367487</td>\n",
       "      <td>0.117851</td>\n",
       "      <td>0.136083</td>\n",
       "      <td>Model Gabungan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.552381</td>\n",
       "      <td>0.675926</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.335640</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.391288</td>\n",
       "      <td>0.124914</td>\n",
       "      <td>0.078567</td>\n",
       "      <td>Model Gabungan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.796296</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.207870</td>\n",
       "      <td>0.311805</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.351543</td>\n",
       "      <td>0.214367</td>\n",
       "      <td>0.078567</td>\n",
       "      <td>Model Gabungan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.078567</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.314270</td>\n",
       "      <td>0.424918</td>\n",
       "      <td>0.078567</td>\n",
       "      <td>Model Gabungan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.419048</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.207870</td>\n",
       "      <td>0.306816</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.350186</td>\n",
       "      <td>0.270031</td>\n",
       "      <td>0.136083</td>\n",
       "      <td>Model Gabungan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.796296</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.207870</td>\n",
       "      <td>0.311805</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.351543</td>\n",
       "      <td>0.214367</td>\n",
       "      <td>0.078567</td>\n",
       "      <td>Model Optimasi</td>\n",
       "      <td>LogReg_5_fold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.283279</td>\n",
       "      <td>0.415740</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.410961</td>\n",
       "      <td>0.294628</td>\n",
       "      <td>0.283279</td>\n",
       "      <td>Model Optimasi</td>\n",
       "      <td>MLP_5_fold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.507937</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.207870</td>\n",
       "      <td>0.311805</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.367487</td>\n",
       "      <td>0.106230</td>\n",
       "      <td>0.136083</td>\n",
       "      <td>Model Optimasi</td>\n",
       "      <td>RandomForest_3_fold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.272166</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.415740</td>\n",
       "      <td>0.424918</td>\n",
       "      <td>0.283279</td>\n",
       "      <td>Model Optimasi</td>\n",
       "      <td>SVC_3_fold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.552381</td>\n",
       "      <td>0.675926</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.335640</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0.391288</td>\n",
       "      <td>0.124914</td>\n",
       "      <td>0.078567</td>\n",
       "      <td>Model Optimasi</td>\n",
       "      <td>XGBoost_5_fold</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model  accuracy_mean  precision_mean  recall_mean   f1_mean  \\\n",
       "0   RandomForest       0.500000        0.333333     0.666667  0.440476   \n",
       "1        XGBoost       0.388889        0.250000     0.277778  0.261905   \n",
       "2         LogReg       0.500000        0.166667     0.222222  0.190476   \n",
       "3            SVC       0.500000        0.333333     0.666667  0.444444   \n",
       "4            MLP       0.555556        0.383333     0.666667  0.476190   \n",
       "5   RandomForest       0.611111        0.416667     0.666667  0.507937   \n",
       "6        XGBoost       0.666667        0.472222     0.666667  0.552381   \n",
       "7         LogReg       0.611111        0.416667     0.500000  0.452381   \n",
       "8            SVC       0.444444        0.166667     0.333333  0.222222   \n",
       "9            MLP       0.555556        0.361111     0.500000  0.419048   \n",
       "10        LogReg       0.611111        0.416667     0.500000  0.452381   \n",
       "11           MLP       0.611111        0.444444     0.500000  0.466667   \n",
       "12  RandomForest       0.611111        0.416667     0.666667  0.507937   \n",
       "13           SVC       0.666667        0.500000     0.666667  0.555556   \n",
       "14       XGBoost       0.666667        0.472222     0.666667  0.552381   \n",
       "\n",
       "    roc_auc_mean  directional_acc_mean  accuracy_std  precision_std  \\\n",
       "0       0.652778              0.500000      0.136083       0.249444   \n",
       "1       0.310185              0.555556      0.207870       0.204124   \n",
       "2       0.717593              0.500000      0.136083       0.235702   \n",
       "3       0.365741              0.500000      0.136083       0.235702   \n",
       "4       0.555556              0.500000      0.207870       0.306413   \n",
       "5       0.833333              0.500000      0.207870       0.311805   \n",
       "6       0.675926              0.611111      0.235702       0.335640   \n",
       "7       0.796296              0.555556      0.207870       0.311805   \n",
       "8       0.583333              0.555556      0.078567       0.235702   \n",
       "9       0.750000              0.500000      0.207870       0.306816   \n",
       "10      0.796296              0.555556      0.207870       0.311805   \n",
       "11      0.791667              0.611111      0.283279       0.415740   \n",
       "12      0.895833              0.500000      0.207870       0.311805   \n",
       "13      0.583333              0.611111      0.272166       0.408248   \n",
       "14      0.675926              0.611111      0.235702       0.335640   \n",
       "\n",
       "    recall_std    f1_std  roc_auc_std  directional_acc_std          source  \\\n",
       "0     0.471405  0.319882     0.199343             0.136083  Model Historis   \n",
       "1     0.207870  0.204817     0.187142             0.078567  Model Historis   \n",
       "2     0.314270  0.269374     0.066448             0.000000  Model Historis   \n",
       "3     0.471405  0.314270     0.371353             0.136083  Model Historis   \n",
       "4     0.471405  0.356348     0.218722             0.136083  Model Historis   \n",
       "5     0.471405  0.367487     0.117851             0.136083  Model Gabungan   \n",
       "6     0.471405  0.391288     0.124914             0.078567  Model Gabungan   \n",
       "7     0.408248  0.351543     0.214367             0.078567  Model Gabungan   \n",
       "8     0.471405  0.314270     0.424918             0.078567  Model Gabungan   \n",
       "9     0.408248  0.350186     0.270031             0.136083  Model Gabungan   \n",
       "10    0.408248  0.351543     0.214367             0.078567  Model Optimasi   \n",
       "11    0.408248  0.410961     0.294628             0.283279  Model Optimasi   \n",
       "12    0.471405  0.367487     0.106230             0.136083  Model Optimasi   \n",
       "13    0.471405  0.415740     0.424918             0.283279  Model Optimasi   \n",
       "14    0.471405  0.391288     0.124914             0.078567  Model Optimasi   \n",
       "\n",
       "             model_name  \n",
       "0                   NaN  \n",
       "1                   NaN  \n",
       "2                   NaN  \n",
       "3                   NaN  \n",
       "4                   NaN  \n",
       "5                   NaN  \n",
       "6                   NaN  \n",
       "7                   NaN  \n",
       "8                   NaN  \n",
       "9                   NaN  \n",
       "10        LogReg_5_fold  \n",
       "11           MLP_5_fold  \n",
       "12  RandomForest_3_fold  \n",
       "13           SVC_3_fold  \n",
       "14       XGBoost_5_fold  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Korelasi antara F1 mean dan F1 std: 0.82\n"
     ]
    }
   ],
   "source": [
    "# Korelasi Pearson antara F1 mean dan std\n",
    "correlation = df_all['f1_mean'].corr(df_all['f1_std'], method='pearson')\n",
    "\n",
    "print(f\"Korelasi antara F1 mean dan F1 std: {correlation:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(data=df_all, x='f1_mean', y='f1_std', hue='source')\n",
    "plt.title(\"Trade-off antara F1 Mean dan Std\")\n",
    "plt.xlabel(\"F1 Mean\")\n",
    "plt.ylabel(\"F1 Std\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(\n",
    "    data=df_all,\n",
    "    x=\"f1_mean\",\n",
    "    y=\"f1_std\",\n",
    "    hue=\"source\",\n",
    "    palette={\"Model Historis\": \"blue\", \"Model Gabungan\": \"green\", \"Model Optimasi\": \"red\"},\n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "# Tambahkan jitter kecil secara manual jika perlu\n",
    "df_jittered = df_all.copy()\n",
    "df_jittered['f1_mean'] += np.random.normal(0, 0.001, size=len(df_all))  # jitter di mean\n",
    "df_jittered['f1_std'] += np.random.normal(0, 0.001, size=len(df_all))   # jitter di std\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df_jittered[df_jittered['source'] == 'Model Gabungan'],\n",
    "    x=\"f1_mean\",\n",
    "    y=\"f1_std\",\n",
    "    color=\"green\",\n",
    "    marker='o',\n",
    "    edgecolor='black'\n",
    ")\n",
    "plt.title(\"Scatter Plot dengan Jitter (Model Gabungan)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gabungkan mean dan std sebagai string anotasi\n",
    "df_all['f1_label'] = df_all.apply(lambda x: f\"{x['f1_mean']:.2f}  {x['f1_std']:.2f}\", axis=1)\n",
    "\n",
    "# Pivot untuk heatmap dengan anotasi gabungan\n",
    "pivot_val = df_all.pivot(index='source', columns='model', values='f1_mean')\n",
    "pivot_label = df_all.pivot(index='source', columns='model', values='f1_label')\n",
    "\n",
    "# Visualisasi heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(pivot_val, annot=pivot_label, cmap='YlGnBu', fmt=\"\", cbar_kws={'label': 'F1 Score'})\n",
    "plt.title(\"F1 Score Heatmap (Mean  Std)\")\n",
    "plt.xlabel(\"Algoritma\")\n",
    "plt.ylabel(\"Model\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMxd9YIyjVud9QMQEbq6P7W",
   "provenance": [
    {
     "file_id": "1UFuyQhFZUvXOZ-EG8A82wy14RuEZD0E4",
     "timestamp": 1752980419944
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
